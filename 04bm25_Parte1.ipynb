{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T19:16:23.971513Z",
     "start_time": "2025-11-23T19:16:18.284072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ],
   "id": "3629627b30a274e5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T19:17:44.020522Z",
     "start_time": "2025-11-23T19:17:42.833538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Cargar el corpus de noticias sin cabeceras, pies de página y citas\n",
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "newsgroupsdocs = newsgroups.data"
   ],
   "id": "b9e0bcab3217900f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T19:23:48.335573Z",
     "start_time": "2025-11-23T19:23:42.642123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Normalización básica: minúsculas, quitar saltos de línea, tabs y símbolos raros\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('\\n', ' ').replace('\\t', ' ')\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Aplicamos la normalización a todos los documentos\n",
    "docs = [normalize_text(doc) for doc in newsgroupsdocs]\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    stopwords = {\n",
    "        \"the\", \"is\", \"in\", \"and\", \"to\", \"of\", \"a\", \"for\", \"on\", \"that\", \"it\",\n",
    "        \"this\", \"as\", \"with\", \"by\", \"an\", \"are\", \"from\", \"at\", \"be\", \"was\",\n",
    "        \"or\", \"which\", \"we\", \"can\", \"has\", \"have\", \"will\", \"not\", \"if\", \"but\",\n",
    "        \"about\", \"there\", \"their\", \"they\", \"you\", \"your\", \"our\", \"my\", \"me\",\n",
    "        \"all\", \"also\", \"so\", \"what\", \"when\", \"where\", \"how\", \"who\", \"do\", \"does\",\n",
    "        \"did\", \"would\", \"could\", \"should\", \"may\", \"might\", \"must\", \"been\", \"being\",\n",
    "        \"am\", \"i\"\n",
    "    }\n",
    "    filtered_tokens = [word for word in tokens if word not in stopwords]\n",
    "    return filtered_tokens\n",
    "\n",
    "# Stemming\n",
    "def simple_stem(word):\n",
    "    word = re.sub(r'(ss|ies|s)$', '', word)\n",
    "    word = re.sub(r'(ing|ed)$', '', word)\n",
    "    word = re.sub(r'(er|est)$', '', word)\n",
    "    word = re.sub(r'ly$', '', word)\n",
    "    return word\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [simple_stem(token) for token in tokens]\n",
    "\n",
    "# Tokenización y pipeline de preprocesamiento\n",
    "def tokenize(text):\n",
    "    return re.findall(r'\\b[a-z]{2,}\\b', text)\n",
    "\n",
    "def preprocesamiento(text):\n",
    "    # Aquí el texto ya está normalizado\n",
    "    tokens = tokenize(text)\n",
    "    filtered = remove_stopwords(tokens)\n",
    "    stemmed = stem_tokens(filtered)\n",
    "    return stemmed\n",
    "\n",
    "# Procesar todos los documentos\n",
    "print(\"\\n✓ Aplicando tokenización, eliminación de stopwords y stemming...\")\n",
    "docs_procesados = [preprocesamiento(doc) for doc in docs]\n",
    "\n",
    "print(f\"✓ Documentos procesados: {len(docs_procesados)}\")\n",
    "print(f\"\\nPrimer documento procesado (10 primeros tokens):\")\n",
    "print(docs_procesados[0][:10])"
   ],
   "id": "68154584a3c148f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Aplicando tokenización, eliminación de stopwords y stemming...\n",
      "✓ Documentos procesados: 18846\n",
      "\n",
      "Primer documento procesado (10 primeros tokens):\n",
      "['sure', 'some', 'bash', 'pen', 'fan', 'pretty', 'confus', 'lack', 'any', 'kind']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T19:25:45.579797Z",
     "start_time": "2025-11-23T19:25:44.353070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PARTE 1: CÁLCULO DE TF, DF, IDF Y TF-IDF\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nConstruyendo matriz TF y calculando DF\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Juntamos los tokens de cada documento otra vez en una sola cadena de texto\n",
    "docs_procesados_texto = [' '.join(doc) for doc in docs_procesados]\n",
    "\n",
    "# Matriz de términos (TF) usando CountVectorizer\n",
    "vectorizer_tf = CountVectorizer()\n",
    "matriz_tf = vectorizer_tf.fit_transform(docs_procesados_texto)\n",
    "\n",
    "# Lista de términos del vocabulario\n",
    "terminos = vectorizer_tf.get_feature_names_out()\n",
    "\n",
    "# Document Frequency (DF): en cuántos documentos aparece cada término\n",
    "df_frecuencias = np.array((matriz_tf > 0).sum(axis=0)).flatten()\n",
    "\n",
    "# DataFrame con info básica de cada término\n",
    "df_tf_df = pd.DataFrame({\n",
    "    'termino': terminos,\n",
    "    'document_frequency': df_frecuencias,\n",
    "    'total_occurrences': np.array(matriz_tf.sum(axis=0)).flatten()\n",
    "})\n",
    "\n",
    "# Ordenamos por DF de mayor a menor\n",
    "df_tf_df = df_tf_df.sort_values('document_frequency', ascending=False)\n",
    "\n",
    "print(f\"✓ Dimensión de la matriz TF: {matriz_tf.shape}\")\n",
    "print(f\"✓ Número de términos distintos: {len(terminos)}\")\n",
    "print(f\"✓ Número de documentos: {matriz_tf.shape[0]}\")"
   ],
   "id": "860ca8b659d013d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PARTE 1: CÁLCULO DE TF, DF, IDF Y TF-IDF\n",
      "======================================================================\n",
      "\n",
      "Construyendo matriz TF y calculando DF\n",
      "--------------------------------------------------\n",
      "✓ Dimensión de la matriz TF: (18846, 77651)\n",
      "✓ Número de términos distintos: 77651\n",
      "✓ Número de documentos: 18846\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T19:29:19.378981Z",
     "start_time": "2025-11-23T19:29:19.375132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nTop 10 términos por frecuencia de documentos (DF):\")\n",
    "print(\"-\" * 50)\n",
    "print(df_tf_df.head(10).to_string(index=False))"
   ],
   "id": "12813aeb4bfe9ba9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 términos por frecuencia de documentos (DF):\n",
      "--------------------------------------------------\n",
      "termino  document_frequency  total_occurrences\n",
      "    one                5435              10979\n",
      "    any                4774               7846\n",
      "   like                4511               7270\n",
      "   some                4333               7865\n",
      "     no                4321               8307\n",
      "    out                4213               7300\n",
      "   know                4104               6466\n",
      "   just                4090               6193\n",
      "    oth                3984               7638\n",
      "    get                3898               6423\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T19:33:58.115279Z",
     "start_time": "2025-11-23T19:33:56.717492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Calculando TF-IDF con sklearn\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "#TfidfVectorizer sobre los textos ya procesados\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "matriz_tfidf = tfidf_vectorizer.fit_transform(docs_procesados_texto)\n",
    "\n",
    "terminos_tfidf = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "print(f\"Dimensión de la matriz TF-IDF: {matriz_tfidf.shape}\")"
   ],
   "id": "f4e3b10ab307f402",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Calculando TF-IDF con sklearn\n",
      "---------------------------------------------\n",
      "Dimensión de la matriz TF-IDF: (18846, 77651)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T19:36:39.436774Z",
     "start_time": "2025-11-23T19:36:39.422656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Comparación: TF/DF vs TF-IDF\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Nos quedamos con los primeros 5 documentos para ver valores concretos\n",
    "tfidf_dense = matriz_tfidf[:5, :].toarray()\n",
    "tf_dense = matriz_tf[:5, :].toarray()\n",
    "\n",
    "# Índices de los términos más frecuentes según DF\n",
    "top_terminos_indices = df_tf_df.index[:30]\n",
    "\n",
    "comparison_data = []\n",
    "for idx in top_terminos_indices[:15]:  # mostramos solo 15 filas\n",
    "    termino = terminos[idx]\n",
    "    df_val = df_frecuencias[idx]\n",
    "    tf_promedio = tf_dense[:, idx].mean()\n",
    "    tfidf_promedio = tfidf_dense[:, idx].mean()\n",
    "\n",
    "    comparison_data.append({\n",
    "        'termino': termino,\n",
    "        'document_frequency': df_val,\n",
    "        'tf_promedio': round(tf_promedio, 4),\n",
    "        'tfidf_promedio': round(tfidf_promedio, 6)\n",
    "    })\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "print(df_comparison.to_string(index=False))"
   ],
   "id": "9734d1b461135ac3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Comparación: TF/DF vs TF-IDF\n",
      "-------------------------------------------------------\n",
      "termino  document_frequency  tf_promedio  tfidf_promedio\n",
      "    one                5435          0.6        0.024080\n",
      "    any                4774          0.6        0.027679\n",
      "   like                4511          0.4        0.012728\n",
      "   some                4333          0.4        0.015059\n",
      "     no                4321          0.2        0.010032\n",
      "    out                4213          0.4        0.014786\n",
      "   know                4104          0.6        0.027094\n",
      "   just                4090          0.2        0.008790\n",
      "    oth                3984          0.8        0.033377\n",
      "    get                3898          0.0        0.000000\n",
      "    don                3894          0.4        0.013499\n",
      "   more                3782          0.2        0.010573\n",
      "     up                3727          0.0        0.000000\n",
      "     on                3496          0.0        0.000000\n",
      "  think                3427          0.2        0.006602\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "bcaaa6c5a0cd2d0d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T19:56:20.581328Z",
     "start_time": "2025-11-23T19:56:20.531353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RANKING DE DOCUMENTOS USANDO TF-IDF\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Función para obtener el ranking de documentos usando TF-IDF\n",
    "def ranking_tfidf(consulta, matriz_tfidf, vectorizer, top_n=10):\n",
    "    # Pasamos la consulta por el mismo preprocesamiento que los docs\n",
    "    consulta_procesada = preprocesamiento(consulta)\n",
    "    consulta_texto = ' '.join(consulta_procesada)\n",
    "\n",
    "    # Representamos la consulta en el espacio TF-IDF\n",
    "    vector_consulta = vectorizer.transform([consulta_texto])\n",
    "\n",
    "    # Similaridad coseno entre la consulta y cada documento\n",
    "    similitudes = cosine_similarity(vector_consulta, matriz_tfidf).flatten()\n",
    "\n",
    "    # Índices de los docs ordenados de mayor a menor similitud\n",
    "    indices_ranking = similitudes.argsort()[::-1]\n",
    "\n",
    "    # Armamos la tabla de resultados\n",
    "    resultados = []\n",
    "    for i, idx in enumerate(indices_ranking[:top_n]):\n",
    "        texto_original = docs[idx]\n",
    "        muestra = texto_original[:100] + '...' if len(texto_original) > 100 else texto_original\n",
    "\n",
    "        resultados.append({\n",
    "            'Rank': i + 1,\n",
    "            'Doc_ID': idx,\n",
    "            'Similitud': round(similitudes[idx], 4),\n",
    "            'Texto_Muestra': muestra\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(resultados)\n",
    "\n",
    "# Ejemplo rápido de búsqueda\n",
    "query= \"government secret conspiracy \"\n",
    "print(f\"Consulta original: '{query}'\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "df_ranking = ranking_tfidf(query, matriz_tfidf, tfidf_vectorizer)\n",
    "print(df_ranking.to_string(index=False))"
   ],
   "id": "24c1c142eb10b747",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RANKING DE DOCUMENTOS USANDO TF-IDF\n",
      "======================================================================\n",
      "Consulta original: 'government secret conspiracy '\n",
      "------------------------------------------------------------\n",
      " Rank  Doc_ID  Similitud                                                                                           Texto_Muestra\n",
      "    1   15813     0.4880                                                            government maintaining a secret of some kind\n",
      "    2    5818     0.2797 jason i ve heard the people who are talking about this dismissed as conspiracy nuts but nobody seems...\n",
      "    3   17608     0.2468 it will be ironic in the extreme if spector manages to uncover a government conspiracy and cover up ...\n",
      "    4   11308     0.2210 dear senator congressman president fill in the blank i am writing you to voice my strong opposition ...\n",
      "    5   15412     0.2198 how about tell everyone what the hell they were doing there in the first place if we knew that we d ...\n",
      "    6    1282     0.2153 the price you have on the seems very good i too would like to know where it is from if it is not giv...\n",
      "    7   18575     0.2079 i think it very unlikely there are back doors in clipper for two reasons the government doesn t need...\n",
      "    8    5726     0.2045                       i wouldn t think so asking people to trust a secret algorithm seems unsound to me\n",
      "    9   15523     0.2037 right people here believe the government is listening in on everything sure if you can t provide an ...\n",
      "   10    5905     0.1958 you have underlined here the battle that must be fought it is a battle for the hearts and minds of t...\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "1feb07381e98af81"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
