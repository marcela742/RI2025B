{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "notebookf9c34c4b73",
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "state": {},
        "version_major": 2,
        "version_minor": 0
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sistema de Recuperación de Información"
      ],
      "metadata": {
        "id": "D5WS7sAdff8E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nombre: Marcela Cabrera"
      ],
      "metadata": {
        "id": "2c06tPzOfnvF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalación de dependencias necesarias"
      ],
      "metadata": {
        "id": "UqTEN7MffzaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ir-datasets sentence-transformers faiss-cpu nltk pandas numpy scikit-learn tqdm\n",
        "\n",
        "import ir_datasets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
        "import faiss\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Descargar recursos de NLTK\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZQVTs5Nf24z",
        "outputId": "ecf9e812-a5cd-4f99-b79d-afc8f7faa866"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ir-datasets in /usr/local/lib/python3.12/dist-packages (0.5.11)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from ir-datasets) (4.13.5)\n",
            "Requirement already satisfied: inscriptis>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from ir-datasets) (2.7.0)\n",
            "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.12/dist-packages (from ir-datasets) (5.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ir-datasets) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.12/dist-packages (from ir-datasets) (2.32.4)\n",
            "Requirement already satisfied: trec-car-tools>=2.5.4 in /usr/local/lib/python3.12/dist-packages (from ir-datasets) (2.6)\n",
            "Requirement already satisfied: lz4>=3.1.10 in /usr/local/lib/python3.12/dist-packages (from ir-datasets) (4.4.5)\n",
            "Requirement already satisfied: warc3-wet>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from ir-datasets) (0.2.5)\n",
            "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /usr/local/lib/python3.12/dist-packages (from ir-datasets) (0.2.5)\n",
            "Requirement already satisfied: zlib-state>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from ir-datasets) (0.1.10)\n",
            "Requirement already satisfied: ijson>=3.1.3 in /usr/local/lib/python3.12/dist-packages (from ir-datasets) (3.4.0.post0)\n",
            "Requirement already satisfied: unlzw3>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from ir-datasets) (0.2.3)\n",
            "Requirement already satisfied: pyarrow>=16.1.0 in /usr/local/lib/python3.12/dist-packages (from ir-datasets) (18.1.0)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cu126)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets) (2.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.22.0->ir-datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.22.0->ir-datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.22.0->ir-datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.22.0->ir-datasets) (2026.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: cbor>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from trec-car-tools>=2.5.4->ir-datasets) (1.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carga del corpus"
      ],
      "metadata": {
        "id": "ZBXJ2s6Nf_4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"Cornell-University/arxiv\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9G0BkCfeTE9",
        "outputId": "dad12098-3946-4d44-e2e5-9c1a48cf289b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.1).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/Cornell-University/arxiv?dataset_version_number=270...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.56G/1.56G [01:16<00:00, 21.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/Cornell-University/arxiv/versions/270\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. PREPROCESAMIENTO DE DATOS:\n",
        " En esta etapa vamos a:\n",
        "\n",
        "Cargar el archivo JSON de arXiv que contiene metadata de papers científicos\n",
        "Limpiar y normalizar los textos (títulos y abstracts)\n",
        "\n",
        "Aplicar técnicas de NLP: tokenización, eliminación de stopwords, stemming\n",
        "\n",
        "Preparar los datos en un formato estructurado para procesamiento posterior"
      ],
      "metadata": {
        "id": "UegHN9jWg1dB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextPreprocessor:\n",
        "    \"\"\"\n",
        "    Clase para preprocesar texto científico.\n",
        "    Aplica: normalización, tokenización, eliminación de stopwords y stemming.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "        self.stemmer = PorterStemmer()\n",
        "\n",
        "    def preprocess(self, text):\n",
        "        if not text or pd.isna(text):\n",
        "            return \"\"\n",
        "\n",
        "        # Normalización a minúsculas\n",
        "        text = text.lower()\n",
        "\n",
        "        # Tokenización\n",
        "        tokens = word_tokenize(text)\n",
        "\n",
        "        # Eliminación de stopwords y caracteres no alfanuméricos\n",
        "        tokens = [token for token in tokens\n",
        "                 if token.isalnum() and token not in self.stop_words]\n",
        "\n",
        "        # Stemming (reducir palabras a su raíz)\n",
        "        tokens = [self.stemmer.stem(token) for token in tokens]\n",
        "\n",
        "        return ' '.join(tokens)\n",
        "\n",
        "# Inicializar preprocesador\n",
        "preprocessor = TextPreprocessor()\n",
        "print(\"✓ Preprocesador inicializado\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ym-6J51jg-dj",
        "outputId": "f27cf752-cd24-4621-96b3-abc7f851ad61"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Preprocesador inicializado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "# Cargar el dataset de arXiv\n",
        "print(\"=\"*80)\n",
        "print(\"CARGANDO DATASET ARXIV\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Ruta al archivo JSON descargado\n",
        "dataset_path = \"/root/.cache/kagglehub/datasets/Cornell-University/arxiv/versions/270\"\n",
        "json_file = os.path.join(dataset_path, \"arxiv-metadata-oai-snapshot.json\")\n",
        "\n",
        "print(f\"\\nArchivo: {json_file}\")\n",
        "print(f\"Tamaño del archivo: {os.path.getsize(json_file) / (1024**3):.2f} GB\")\n",
        "\n",
        "def load_arxiv_papers(filepath, max_papers=30000, categories_filter=None):\n",
        "    \"\"\"\n",
        "    Carga papers de arXiv desde el archivo JSON.\n",
        "\n",
        "    Args:\n",
        "        filepath: ruta al archivo JSON\n",
        "        max_papers: número máximo de papers a cargar\n",
        "        categories_filter: lista de categorías a filtrar (ej: ['cs.AI', 'cs.LG'])\n",
        "    \"\"\"\n",
        "    papers = []\n",
        "\n",
        "    print(f\"\\nCargando hasta {max_papers:,} papers...\")\n",
        "    if categories_filter:\n",
        "        print(f\"Filtrando por categorías: {categories_filter}\")\n",
        "\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        for i, line in enumerate(tqdm(f, desc=\"Procesando\")):\n",
        "            if len(papers) >= max_papers:\n",
        "                break\n",
        "\n",
        "            try:\n",
        "                paper = json.loads(line)\n",
        "\n",
        "                # Filtrar por categoría si se especifica\n",
        "                if categories_filter:\n",
        "                    paper_cats = paper.get('categories', '').split()\n",
        "                    if not any(cat in categories_filter for cat in paper_cats):\n",
        "                        continue\n",
        "\n",
        "                papers.append({\n",
        "                    'id': paper.get('id', ''),\n",
        "                    'title': paper.get('title', ''),\n",
        "                    'abstract': paper.get('abstract', ''),\n",
        "                    'authors': paper.get('authors', ''),\n",
        "                    'categories': paper.get('categories', ''),\n",
        "                    'submitter': paper.get('submitter', ''),\n",
        "                    'doi': paper.get('doi', ''),\n",
        "                    'journal-ref': paper.get('journal-ref', ''),\n",
        "                    'comments': paper.get('comments', ''),\n",
        "                    'update_date': paper.get('update_date', '')\n",
        "                })\n",
        "\n",
        "            except (json.JSONDecodeError, Exception) as e:\n",
        "                continue\n",
        "\n",
        "    return pd.DataFrame(papers)\n",
        "\n",
        "# Cargar papers (puedes filtrar por categorías de interés)\n",
        "# Ejemplo: solo Computer Science y Machine Learning\n",
        "cs_categories = ['cs.AI', 'cs.LG', 'cs.CL', 'cs.CV', 'cs.IR', 'cs.NE']\n",
        "\n",
        "docs_df = load_arxiv_papers(\n",
        "    json_file,\n",
        "    max_papers=30000,  # Ajusta según tu RAM disponible\n",
        "    categories_filter=None  # None = todas las categorías, o usa cs_categories\n",
        ")\n",
        "\n",
        "print(f\"\\n✓ Papers cargados: {len(docs_df):,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF7IxARagEb9",
        "outputId": "2eb6e6e3-7abe-4212-c40d-da0cb79e91e4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "CARGANDO DATASET ARXIV\n",
            "================================================================================\n",
            "\n",
            "Archivo: /root/.cache/kagglehub/datasets/Cornell-University/arxiv/versions/270/arxiv-metadata-oai-snapshot.json\n",
            "Tamaño del archivo: 4.72 GB\n",
            "\n",
            "Cargando hasta 30,000 papers...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando: 30000it [00:00, 70783.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Papers cargados: 30,000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Limpiar y preprocesar los textos\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PREPROCESAMIENTO DE TEXTOS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Limpiar saltos de línea y espacios extra en títulos y abstracts\n",
        "print(\"\\n1. Limpiando formato...\")\n",
        "docs_df['title_clean'] = docs_df['title'].str.replace('\\n', ' ').str.replace('  ', ' ').str.strip()\n",
        "docs_df['abstract_clean'] = docs_df['abstract'].str.replace('\\n', ' ').str.replace('  ', ' ').str.strip()\n",
        "\n",
        "# Crear texto completo (título + abstract)\n",
        "print(\"2. Combinando título y abstract...\")\n",
        "docs_df['full_text'] = docs_df['title_clean'] + '. ' + docs_df['abstract_clean']\n",
        "\n",
        "# Aplicar preprocesamiento (tokenización, stemming, etc.)\n",
        "print(\"3. Aplicando tokenización, stemming y eliminación de stopwords...\")\n",
        "tqdm.pandas(desc=\"Preprocesando\")\n",
        "docs_df['preprocessed'] = docs_df['full_text'].progress_apply(preprocessor.preprocess)\n",
        "\n",
        "# Eliminar papers sin abstract\n",
        "docs_df = docs_df[docs_df['abstract_clean'].str.len() > 50].reset_index(drop=True)\n",
        "\n",
        "print(f\"\\n✓ Papers procesados: {len(docs_df):,}\")\n",
        "print(f\"\\nEjemplo de paper preprocesado:\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"ID: {docs_df.iloc[0]['id']}\")\n",
        "print(f\"Título original: {docs_df.iloc[0]['title_clean'][:100]}...\")\n",
        "print(f\"Abstract original: {docs_df.iloc[0]['abstract_clean'][:150]}...\")\n",
        "print(f\"Preprocesado: {docs_df.iloc[0]['preprocessed'][:150]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gc-dQGLiDOH",
        "outputId": "1af4cdbd-4a58-475c-b0a0-d4f010eecaa1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "PREPROCESAMIENTO DE TEXTOS\n",
            "================================================================================\n",
            "\n",
            "1. Limpiando formato...\n",
            "2. Combinando título y abstract...\n",
            "3. Aplicando tokenización, stemming y eliminación de stopwords...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Preprocesando: 100%|██████████| 30000/30000 [01:01<00:00, 489.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Papers procesados: 29,957\n",
            "\n",
            "Ejemplo de paper preprocesado:\n",
            "--------------------------------------------------------------------------------\n",
            "ID: 0704.0001\n",
            "Título original: Calculation of prompt diphoton production cross sections at Tevatron and  LHC energies...\n",
            "Abstract original: A fully differential calculation in perturbative quantum chromodynamics is presented for the production of massive photon pairs at hadron colliders. A...\n",
            "Preprocesado: calcul prompt diphoton product cross section tevatron lhc energi fulli differenti calcul perturb quantum chromodynam present product massiv photon pai...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. CREACIÓN DE CONSULTAS Y QRELS\n",
        "Como arXiv no tiene consultas predefinidas ni juicios de relevancia (qrels), vamos a:\n",
        "\n",
        "Crear consultas de ejemplo relevantes para diferentes áreas científicas\n",
        "\n",
        "Generar qrels automáticos basados en similitud de categorías y keywords\n"
      ],
      "metadata": {
        "id": "NN9-sQkhjFZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CREACIÓN DE CONSULTAS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Definir consultas representativas de diferentes dominios científicos\n",
        "queries_list = [\n",
        "    {\n",
        "        'query_id': 'Q001',\n",
        "        'title': 'Deep learning convolutional neural networks',\n",
        "        'description': 'Papers about deep learning using convolutional neural networks for image processing and computer vision',\n",
        "        'narrative': 'Find research papers discussing CNN architectures, deep learning models for visual recognition, image classification, or object detection using neural networks'\n",
        "    },\n",
        "    {\n",
        "        'query_id': 'Q002',\n",
        "        'title': 'Natural language processing transformer models',\n",
        "        'description': 'Research on transformer-based models for natural language understanding',\n",
        "        'narrative': 'Find papers about transformer architectures, attention mechanisms, BERT, GPT, or other language models for NLP tasks'\n",
        "    },\n",
        "    {\n",
        "        'query_id': 'Q003',\n",
        "        'title': 'Reinforcement learning algorithms',\n",
        "        'description': 'Papers on reinforcement learning methods and applications',\n",
        "        'narrative': 'Find research on RL algorithms, policy gradient methods, Q-learning, deep reinforcement learning, or multi-agent systems'\n",
        "    },\n",
        "    {\n",
        "        'query_id': 'Q004',\n",
        "        'title': 'Graph neural networks',\n",
        "        'description': 'Graph-based deep learning and neural network architectures',\n",
        "        'narrative': 'Find papers about GNN architectures, graph convolutional networks, message passing, or graph representation learning'\n",
        "    },\n",
        "    {\n",
        "        'query_id': 'Q005',\n",
        "        'title': 'Quantum computing algorithms',\n",
        "        'description': 'Quantum algorithms and quantum information processing',\n",
        "        'narrative': 'Find research on quantum algorithms, quantum gates, quantum circuits, quantum error correction, or quantum machine learning'\n",
        "    },\n",
        "    {\n",
        "        'query_id': 'Q006',\n",
        "        'title': 'Generative adversarial networks',\n",
        "        'description': 'GAN architectures and applications for generative modeling',\n",
        "        'narrative': 'Find papers about GAN training, generative models, image synthesis, or adversarial learning techniques'\n",
        "    },\n",
        "    {\n",
        "        'query_id': 'Q007',\n",
        "        'title': 'Transfer learning domain adaptation',\n",
        "        'description': 'Transfer learning methods and domain adaptation techniques',\n",
        "        'narrative': 'Find research on transfer learning, domain adaptation, few-shot learning, or meta-learning approaches'\n",
        "    },\n",
        "    {\n",
        "        'query_id': 'Q008',\n",
        "        'title': 'Time series forecasting',\n",
        "        'description': 'Methods for time series prediction and forecasting',\n",
        "        'narrative': 'Find papers about time series analysis, LSTM networks, temporal modeling, or sequence prediction methods'\n",
        "    },\n",
        "    {\n",
        "        'query_id': 'Q009',\n",
        "        'title': 'Explainable artificial intelligence',\n",
        "        'description': 'Interpretability and explainability in machine learning models',\n",
        "        'narrative': 'Find research on model interpretability, explainable AI, feature importance, or attention visualization'\n",
        "    },\n",
        "    {\n",
        "        'query_id': 'Q010',\n",
        "        'title': 'Federated learning privacy',\n",
        "        'description': 'Federated learning and privacy-preserving machine learning',\n",
        "        'narrative': 'Find papers about federated learning, differential privacy, secure multi-party computation, or privacy-preserving AI'\n",
        "    }\n",
        "]\n",
        "\n",
        "queries_df = pd.DataFrame(queries_list)\n",
        "\n",
        "# Crear texto completo de la consulta\n",
        "queries_df['full_text'] = (queries_df['title'] + '. ' +\n",
        "                           queries_df['description'] + '. ' +\n",
        "                           queries_df['narrative'])\n",
        "\n",
        "# Preprocesar consultas\n",
        "queries_df['preprocessed'] = queries_df['full_text'].apply(preprocessor.preprocess)\n",
        "\n",
        "print(f\"✓ Consultas creadas: {len(queries_df)}\")\n",
        "print(\"\\nConsultas:\")\n",
        "for idx, row in queries_df.iterrows():\n",
        "    print(f\"  {row['query_id']}: {row['title']}\")"
      ],
      "metadata": {
        "id": "Bu56BQ__jhFN",
        "outputId": "8d920548-566e-4dff-8244-112fe87fc9c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "CREACIÓN DE CONSULTAS\n",
            "================================================================================\n",
            "✓ Consultas creadas: 10\n",
            "\n",
            "Consultas:\n",
            "  Q001: Deep learning convolutional neural networks\n",
            "  Q002: Natural language processing transformer models\n",
            "  Q003: Reinforcement learning algorithms\n",
            "  Q004: Graph neural networks\n",
            "  Q005: Quantum computing algorithms\n",
            "  Q006: Generative adversarial networks\n",
            "  Q007: Transfer learning domain adaptation\n",
            "  Q008: Time series forecasting\n",
            "  Q009: Explainable artificial intelligence\n",
            "  Q010: Federated learning privacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"GENERACIÓN DE QRELS (Juicios de Relevancia)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def create_qrels_for_arxiv(queries_df, docs_df):\n",
        "    \"\"\"\n",
        "    Crea qrels automáticos basados en:\n",
        "    1. Coincidencia de keywords en título y abstract\n",
        "    2. Similitud de categorías\n",
        "    3. Scoring basado en múltiples criterios\n",
        "    \"\"\"\n",
        "\n",
        "    # Definir keywords por cada consulta\n",
        "    query_keywords = {\n",
        "        'Q001': {\n",
        "            'primary': ['deep learning', 'cnn', 'convolutional', 'neural network'],\n",
        "            'secondary': ['image', 'vision', 'classification', 'recognition'],\n",
        "            'categories': ['cs.CV', 'cs.LG', 'cs.AI']\n",
        "        },\n",
        "        'Q002': {\n",
        "            'primary': ['transformer', 'bert', 'gpt', 'attention'],\n",
        "            'secondary': ['nlp', 'language model', 'natural language'],\n",
        "            'categories': ['cs.CL', 'cs.LG', 'cs.AI']\n",
        "        },\n",
        "        'Q003': {\n",
        "            'primary': ['reinforcement learning', 'rl', 'policy gradient', 'q-learning'],\n",
        "            'secondary': ['agent', 'reward', 'markov'],\n",
        "            'categories': ['cs.LG', 'cs.AI', 'stat.ML']\n",
        "        },\n",
        "        'Q004': {\n",
        "            'primary': ['graph neural', 'gnn', 'gcn', 'graph convolutional'],\n",
        "            'secondary': ['node', 'edge', 'graph representation'],\n",
        "            'categories': ['cs.LG', 'cs.AI', 'stat.ML']\n",
        "        },\n",
        "        'Q005': {\n",
        "            'primary': ['quantum', 'qubit', 'quantum computing'],\n",
        "            'secondary': ['quantum algorithm', 'quantum gate', 'quantum circuit'],\n",
        "            'categories': ['quant-ph', 'cs.ET']\n",
        "        },\n",
        "        'Q006': {\n",
        "            'primary': ['gan', 'generative adversarial', 'adversarial network'],\n",
        "            'secondary': ['generator', 'discriminator', 'generative model'],\n",
        "            'categories': ['cs.LG', 'cs.CV', 'stat.ML']\n",
        "        },\n",
        "        'Q007': {\n",
        "            'primary': ['transfer learning', 'domain adaptation', 'few-shot'],\n",
        "            'secondary': ['meta-learning', 'adaptation', 'fine-tuning'],\n",
        "            'categories': ['cs.LG', 'cs.AI', 'stat.ML']\n",
        "        },\n",
        "        'Q008': {\n",
        "            'primary': ['time series', 'forecasting', 'temporal'],\n",
        "            'secondary': ['lstm', 'sequence', 'prediction'],\n",
        "            'categories': ['cs.LG', 'stat.ML', 'cs.AI']\n",
        "        },\n",
        "        'Q009': {\n",
        "            'primary': ['explainability', 'interpretability', 'explainable ai'],\n",
        "            'secondary': ['attention', 'visualization', 'feature importance'],\n",
        "            'categories': ['cs.LG', 'cs.AI', 'stat.ML']\n",
        "        },\n",
        "        'Q010': {\n",
        "            'primary': ['federated learning', 'privacy', 'differential privacy'],\n",
        "            'secondary': ['distributed', 'secure', 'privacy-preserving'],\n",
        "            'categories': ['cs.LG', 'cs.CR', 'cs.AI']\n",
        "        }\n",
        "    }\n",
        "\n",
        "    qrels_list = []\n",
        "\n",
        "    print(\"Generando qrels para cada consulta...\")\n",
        "    for query_id, keywords_info in tqdm(query_keywords.items()):\n",
        "        primary_kw = keywords_info['primary']\n",
        "        secondary_kw = keywords_info['secondary']\n",
        "        relevant_cats = keywords_info['categories']\n",
        "\n",
        "        for idx, doc in docs_df.iterrows():\n",
        "            text_lower = (doc['title_clean'] + ' ' + doc['abstract_clean']).lower()\n",
        "            doc_categories = doc['categories'].split()\n",
        "\n",
        "            # Scoring\n",
        "            score = 0\n",
        "\n",
        "            # Primary keywords en título (peso alto)\n",
        "            for kw in primary_kw:\n",
        "                if kw in doc['title_clean'].lower():\n",
        "                    score += 3\n",
        "                elif kw in text_lower:\n",
        "                    score += 2\n",
        "\n",
        "            # Secondary keywords\n",
        "            for kw in secondary_kw:\n",
        "                if kw in text_lower:\n",
        "                    score += 1\n",
        "\n",
        "            # Categorías relevantes\n",
        "            for cat in relevant_cats:\n",
        "                if cat in doc_categories:\n",
        "                    score += 2\n",
        "\n",
        "            # Asignar relevancia basada en score\n",
        "            if score >= 8:\n",
        "                relevance = 2  # Altamente relevante\n",
        "            elif score >= 4:\n",
        "                relevance = 1  # Relevante\n",
        "            else:\n",
        "                continue  # No relevante\n",
        "\n",
        "            qrels_list.append({\n",
        "                'query_id': query_id,\n",
        "                'doc_id': doc['id'],\n",
        "                'relevance': relevance,\n",
        "                'score': score\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(qrels_list)\n",
        "\n",
        "# Generar qrels\n",
        "print(\"\\nGenerando qrels basados en keywords y categorías...\")\n",
        "qrels_df = create_qrels_for_arxiv(queries_df, docs_df)\n",
        "\n",
        "print(f\"\\n✓ Qrels generados: {len(qrels_df):,}\")\n",
        "print(f\"\\nEstadísticas de qrels:\")\n",
        "print(f\"  Consultas con qrels: {qrels_df['query_id'].nunique()}\")\n",
        "print(f\"  Promedio de docs relevantes por query: {len(qrels_df) / qrels_df['query_id'].nunique():.1f}\")\n",
        "\n",
        "print(f\"\\nDistribución de relevancia:\")\n",
        "print(qrels_df['relevance'].value_counts().sort_index())\n",
        "\n",
        "print(f\"\\nQrels por consulta:\")\n",
        "for qid in queries_df['query_id']:\n",
        "    count = len(qrels_df[qrels_df['query_id'] == qid])\n",
        "    print(f\"  {qid}: {count} documentos relevantes\")"
      ],
      "metadata": {
        "id": "rzLcfgS7jqBb",
        "outputId": "6b3c7270-cf18-4f9b-cd70-f38070c5f1c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "GENERACIÓN DE QRELS (Juicios de Relevancia)\n",
            "================================================================================\n",
            "\n",
            "Generando qrels basados en keywords y categorías...\n",
            "Generando qrels para cada consulta...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:16<00:00,  1.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Qrels generados: 1,743\n",
            "\n",
            "Estadísticas de qrels:\n",
            "  Consultas con qrels: 10\n",
            "  Promedio de docs relevantes por query: 174.3\n",
            "\n",
            "Distribución de relevancia:\n",
            "relevance\n",
            "1    1660\n",
            "2      83\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Qrels por consulta:\n",
            "  Q001: 50 documentos relevantes\n",
            "  Q002: 41 documentos relevantes\n",
            "  Q003: 66 documentos relevantes\n",
            "  Q004: 18 documentos relevantes\n",
            "  Q005: 1449 documentos relevantes\n",
            "  Q006: 13 documentos relevantes\n",
            "  Q007: 18 documentos relevantes\n",
            "  Q008: 52 documentos relevantes\n",
            "  Q009: 20 documentos relevantes\n",
            "  Q010: 16 documentos relevantes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. REPRESENTACIÓN MEDIANTE EMBEDDINGS\n",
        "\n",
        " Vamos a convertir textos a representaciones vectoriales (embeddings):\n",
        "\n",
        "\n",
        "Los embeddings capturan el significado semántico del texto\n",
        "\n",
        "Esto permite buscar por similitud conceptual, no solo por palabras exactas"
      ],
      "metadata": {
        "id": "cPphmyrJk0Kc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"GENERACIÓN DE EMBEDDINGS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Cargar modelo de embeddings especializado en papers científicos\n",
        "print(\"\\nCargando modelo de embeddings...\")\n",
        "print(\"Modelo: allenai-specter (optimizado para literatura científica)\")\n",
        "\n",
        "try:\n",
        "    embedding_model = SentenceTransformer('allenai-specter')\n",
        "    print(\"✓ Modelo SPECTER cargado\")\n",
        "except:\n",
        "    print(\"⚠ SPECTER no disponible, usando all-MiniLM-L6-v2\")\n",
        "    embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "print(f\"Dimensión de embeddings: {embedding_model.get_sentence_embedding_dimension()}\")"
      ],
      "metadata": {
        "id": "9Fd-T_7ekf9I",
        "outputId": "941b4005-0425-4e7a-d7aa-9a5bd11e670b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525,
          "referenced_widgets": [
            "812990a9639e4da89ec3c931e4373d61",
            "a20f605e8b5246a882aaca8d26b43c34",
            "1d42349c9e0d47b6823276bf324bebf5",
            "da3ee427e30d4758a7ac882b25f3c916",
            "8c3ba35b5d8340119d0b3eacfbc22f22",
            "5bb33e9ef2d6425fa45281ac90bb4fd8",
            "612475454feb4862ae1d999590db9ed0",
            "d408922bfdd14fa7bea4c3366e0d4233",
            "9f4444df830541aca56ded27762cb131",
            "cd5587c4996146019592138763156b03",
            "85beb7531cf148c9ba51866524a1d32f",
            "12b9d757c5874e02a93bc1a8b6372193",
            "2fbcdba4aa94457a932d42ff2f5e9d18",
            "c21019ad66064c25b922c87a307a8b4e",
            "acbd3c1c89404802a950af616329ec33",
            "3435eea306a94594bb496efa06bdded1",
            "67870aae78374d8b88189cb4a67ddeca",
            "1e96da578cd843e9858979a0d4fefb19",
            "1025a0c4826141e58c0a56be44cb1fe2",
            "d042bb7ecd3d49a3ac7680131438a839",
            "7a8491ad5b43469dac1dc7fb52dcb307",
            "81d3ed008ae9437fa00e0020a0d312cd",
            "48ac5994638f4599af6096ec39e90778",
            "cfd094d9f9bf4e4e98931e5f9b7a1bac",
            "f38de2e1e90e428787ed9c6514c90256",
            "6863de93f9194065afe0edfc50a77ee2",
            "0e9825814fa845b385f45e229f0bf90d",
            "d161423321264e92800473b6228731b9",
            "36a95dc685bd44928a54228c1f93ca93",
            "0e79c9a7e8044cebad315ada50f47868",
            "4b7bb72a9e624a15b108202d3238ca32",
            "08b48c803f03467c9befb691451e45e9",
            "fe192da4fbd1408584a3c0973dadaeaa",
            "4f879477e2164977ae9de91ca8526f84",
            "89dbb3512e0e48afaf6986f741cd7cff",
            "9c7552d246984622a49988d7c0635983",
            "7feccffeedaf4c5c8dd47cb4c675c225",
            "bef184ba62b54f278ae58a3c02100cb7",
            "d358e41ddb0e4758ba00294cce542863",
            "7ca78a04497a47de910d01fe098553c1",
            "0a6423615d7242e9af5c2d437a3b3081",
            "0f2df636a84e4b4082e5903cd5c4f631",
            "0ca52cff1ec24beaa5d6af0697d7aeb6",
            "f24a3d15ac62423c9cf4b40a1167e4cf",
            "d39b3aa180024c2093d0197691217586",
            "b28511823a5a4af0905f3bfe198228cc",
            "6733047bd77f45dcb86c50e9fb81b153",
            "9e8ae395e32049c783c7e6a1e0638986",
            "a7a44099e9bc459ab1995b8f74dcb90a",
            "87f73c228e694372995113d324bb6177",
            "618a238d11e64648958b6d7fb624052f",
            "690ffb9740a84dc2bdc0e0b984f5e2a6",
            "7601a2b680374b1fa726272d4305e17f",
            "71370dce77e84db1b6330335dcb45102",
            "06b4849af34647ed9a03b6e97f48950b",
            "6cde32d1cabd45a2b5d01a0d1cf682ad",
            "180f9e2309ff4d31841dbeb46027a7fd",
            "235176cdf544432099878c46fd24c522",
            "3321b526c52340828f9e1520253cf8f3",
            "885c66ef390742179ceb33547b681089",
            "49edf662100c4be1acfd35cab5137bfe",
            "c371bff3f6194c1c81109cb863828a7c",
            "c6639f44bba94433b08d83ab1a3315a8",
            "aa1bb0ca4fe94b9b9c24949c5857cb4c",
            "73fffbfda80d491794267be6d5f34ff8",
            "7951cea031dd4c18be8c8eaa24c8f801",
            "3243cb96cfab4bacaffc741c96830c65",
            "8e2719d82d174ff9b9711f1afe3bb8da",
            "ef78968157b745a9b4a2bd641bc0de5b",
            "41e87f3ccc334094a87291b0be60044e",
            "6396acac5a044177b72479e338cfa29f",
            "8c541fe3e5984d4789795fdce5c91c90",
            "2240fbb318624b9ba7728a96e9971cdc",
            "1829b0d3a12f4006a685654e26d61267",
            "f0dda81114ef409a8ba114455549b7e8",
            "ff588ae6fcd2481db47a57ab996ecc6a",
            "f4168b431e5c45698a0b7e6b180303de",
            "042137ad2fa8472b92a54c53d28bc3b3",
            "22e61711d1f64056b0bbe56a1888b459",
            "a015a4ba49b94aebb79efd6dd18a7099",
            "3e114c33c1514902aa08c988727fd8eb",
            "8976dd0fe88c4a36b5809fa83e42bdb1",
            "86555857e51b4b9fbb532b76ad295094",
            "df853baf1690426197151e51812e736d",
            "4b77f964fe604c25bc6c737ab5986ae6",
            "5dc7a71d28504966b4e1b95037663d95",
            "cd41f08d3fb540c79a55218ae3bb5a60",
            "9a8f9bb8013c41cf9ec11467a56fa475",
            "aaec948cc05c4e569cdcc7df5da088b0",
            "02a0c0ac35f34266991ef6caed746860",
            "c9dd77aa2b2a4cc48466bea6806e3da6",
            "c54061ae628549dda97876ec97cfa796",
            "da6a92d86a74491db31606f709102d1a",
            "046153670f4f48829f61acfd73f7e04d",
            "dae4401683ee4428992649c44a75dda9",
            "41d6c13b07ae4dc19930a9912ddadc1d",
            "962cea1ba6d54522933ab001825c05d4",
            "4b8c0137892a4ce2bb19e1cc1bd5904d",
            "1849e7b394da4c4ca83361dc669b6fd7",
            "c3b736b881d1496babd286bbdb2c6b04",
            "3f0aae8619ef42cbb42ae49451df4f33",
            "bb79b371e19c4a57bf183d9725258a3e",
            "daa002a22d3547c29d00cf19b1b22f90",
            "2fa962ddbdb040b3b3970a70a5a39905",
            "80b5356aee5745b28b0cc778e497b1ac",
            "03878ac058a64a35b4a1592b7f6ec8b1",
            "5972a63f785e412ab0eb5e1b16d776e9",
            "fae62d9247ed4e54a45e7efd556e9acb",
            "7b2f8dca1e5a4064a77b9478f96680cb",
            "be1a115d9b094fcd86d530ef1f3dc561",
            "20b6020be0c74c3ba063617b717dfa2d",
            "520893e63de345b8b01e5b1acaadf4b2",
            "0838a23e932d47f1b2daedf8e6a923b9",
            "684406b37c8049558bde7df66b9e2fef",
            "dec13a46cb514c138227d816c967f0af",
            "c80215f39d3f4629b44b3d9374b68333",
            "6d07dd5fefea4e559cdc48412ac6fdf6",
            "7db28e5e50d54b04b141c04d06a8fcf8",
            "5b291ecc20064430aeeefc08af40fffe",
            "015dcf50c2834193b79aa18b88a095b3",
            "e71bdd1c296b4157bcdd57ae68942b07"
          ]
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "GENERACIÓN DE EMBEDDINGS\n",
            "================================================================================\n",
            "\n",
            "Cargando modelo de embeddings...\n",
            "Modelo: allenai-specter (optimizado para literatura científica)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "812990a9639e4da89ec3c931e4373d61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12b9d757c5874e02a93bc1a8b6372193"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48ac5994638f4599af6096ec39e90778"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f879477e2164977ae9de91ca8526f84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/622 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d39b3aa180024c2093d0197691217586"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cde32d1cabd45a2b5d01a0d1cf682ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/331 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3243cb96cfab4bacaffc741c96830c65"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "042137ad2fa8472b92a54c53d28bc3b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aaec948cc05c4e569cdcc7df5da088b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3b736b881d1496babd286bbdb2c6b04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20b6020be0c74c3ba063617b717dfa2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Modelo SPECTER cargado\n",
            "Dimensión de embeddings: 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generar embeddings para documentos\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EMBEDDINGS DE DOCUMENTOS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "batch_size = 32\n",
        "doc_embeddings = []\n",
        "\n",
        "print(f\"Generando embeddings para {len(docs_df):,} documentos...\")\n",
        "print(f\"Batch size: {batch_size}\")\n",
        "\n",
        "for i in tqdm(range(0, len(docs_df), batch_size), desc=\"Procesando batches\"):\n",
        "    batch_texts = docs_df['full_text'].iloc[i:i+batch_size].tolist()\n",
        "\n",
        "    # Truncar textos muy largos (límite del modelo)\n",
        "    batch_texts = [text[:512] if len(text) > 512 else text for text in batch_texts]\n",
        "\n",
        "    batch_embeddings = embedding_model.encode(\n",
        "        batch_texts,\n",
        "        show_progress_bar=False,\n",
        "        convert_to_numpy=True\n",
        "    )\n",
        "    doc_embeddings.extend(batch_embeddings)\n",
        "\n",
        "doc_embeddings = np.array(doc_embeddings).astype('float32')\n",
        "\n",
        "print(f\"\\n✓ Embeddings de documentos generados\")\n",
        "print(f\"  Shape: {doc_embeddings.shape}\")\n",
        "print(f\"  Tamaño en memoria: {doc_embeddings.nbytes / (1024**2):.2f} MB\")"
      ],
      "metadata": {
        "id": "6JSi3wk0lJrT",
        "outputId": "f3d935de-094a-4b62-ff15-2c341bd9e12c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "EMBEDDINGS DE DOCUMENTOS\n",
            "================================================================================\n",
            "Generando embeddings para 29,957 documentos...\n",
            "Batch size: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando batches: 100%|██████████| 937/937 [04:54<00:00,  3.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Embeddings de documentos generados\n",
            "  Shape: (29957, 768)\n",
            "  Tamaño en memoria: 87.76 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generar embeddings para consultas\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EMBEDDINGS DE CONSULTAS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"Generando embeddings para {len(queries_df)} consultas...\")\n",
        "\n",
        "query_embeddings = embedding_model.encode(\n",
        "    queries_df['full_text'].tolist(),\n",
        "    show_progress_bar=True,\n",
        "    convert_to_numpy=True\n",
        ")\n",
        "query_embeddings = np.array(query_embeddings).astype('float32')\n",
        "\n",
        "print(f\"\\n✓ Embeddings de consultas generados\")\n",
        "print(f\"  Shape: {query_embeddings.shape}\")\n",
        "print(f\"  Tamaño en memoria: {query_embeddings.nbytes / 1024:.2f} KB\")"
      ],
      "metadata": {
        "id": "_R5OJ84OnwfL",
        "outputId": "a3deb63f-ddbd-4e8e-8920-03c0479b825b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "efbcf2e76c3c44bab6c722c7a35a8ea5",
            "a14b98d313674b56afe4f5d0b670a83d",
            "705b8f0a01c142e4992f58c2bf979a98",
            "e51aa9b9d8b44074b4444013604c86b6",
            "5bff5d2643f9436590734bce0cdcfd09",
            "2bc6497e24ca4162b00b2510433a8d40",
            "de85ef8de4d24809834e1510a5343d57",
            "e44d14f52c1e482f8f82917745c8604b",
            "5af7ce84ad6f419f8d56248ea17b7663",
            "3500152a5d044c6ca80167bc5f9b0405",
            "655a76cbdd214d54a6a5edec4c209e20"
          ]
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "EMBEDDINGS DE CONSULTAS\n",
            "================================================================================\n",
            "Generando embeddings para 10 consultas...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efbcf2e76c3c44bab6c722c7a35a8ea5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Embeddings de consultas generados\n",
            "  Shape: (10, 768)\n",
            "  Tamaño en memoria: 30.00 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. RECUPERACIÓN INICIAL CON FAISS\n",
        "\n",
        "\n",
        "FAISS (Facebook AI Similarity Search) permite buscar en millones de vectores rápidamente\n",
        "\n",
        "Usaremos producto interno (Inner Product) como medida de similitud\n",
        "\n",
        "Recuperaremos los top-100 documentos más similares para cada consulta"
      ],
      "metadata": {
        "id": "uU-wUz5nlf3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CREACIÓN DE ÍNDICE FAISS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Obtener dimensión de los embeddings\n",
        "dimension = doc_embeddings.shape[1]\n",
        "print(f\"Dimensión de vectores: {dimension}\")\n",
        "\n",
        "# Crear índice FAISS con Inner Product\n",
        "print(\"\\nCreando índice FAISS (IndexFlatIP)...\")\n",
        "index = faiss.IndexFlatIP(dimension)\n",
        "\n",
        "print(\"Normalizando embeddings para similitud coseno...\")\n",
        "# Normalizar vectores L2 para usar Inner Product como similitud coseno\n",
        "faiss.normalize_L2(doc_embeddings)\n",
        "faiss.normalize_L2(query_embeddings)\n",
        "\n",
        "# Añadir documentos al índice\n",
        "print(\"Indexando documentos...\")\n",
        "index.add(doc_embeddings)\n",
        "\n",
        "print(f\"\\n✓ Índice FAISS creado exitosamente\")\n",
        "print(f\"  Total de vectores indexados: {index.ntotal:,}\")\n",
        "print(f\"  Tipo de índice: {type(index).__name__}\")\n",
        "print(f\"  Es entrenado: {index.is_trained}\")"
      ],
      "metadata": {
        "id": "Mxw9MsjWlmVl",
        "outputId": "84924f5a-f278-4e17-ab69-c328383ce8bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "CREACIÓN DE ÍNDICE FAISS\n",
            "================================================================================\n",
            "Dimensión de vectores: 768\n",
            "\n",
            "Creando índice FAISS (IndexFlatIP)...\n",
            "Normalizando embeddings para similitud coseno...\n",
            "Indexando documentos...\n",
            "\n",
            "✓ Índice FAISS creado exitosamente\n",
            "  Total de vectores indexados: 29,957\n",
            "  Tipo de índice: IndexFlatIP\n",
            "  Es entrenado: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RECUPERACIÓN INICIAL (First-Stage Retrieval)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "k_initial = 100  # Top-k documentos a recuperar\n",
        "initial_results = {}\n",
        "\n",
        "print(f\"Recuperando top-{k_initial} documentos para cada consulta...\")\n",
        "\n",
        "for idx, row in tqdm(queries_df.iterrows(), total=len(queries_df), desc=\"Consultas\"):\n",
        "    query_id = row['query_id']\n",
        "    query_emb = query_embeddings[idx].reshape(1, -1)\n",
        "\n",
        "    # Buscar en el índice\n",
        "    scores, indices = index.search(query_emb, k_initial)\n",
        "\n",
        "    # Guardar resultados\n",
        "    initial_results[query_id] = {\n",
        "        'doc_ids': [docs_df.iloc[i]['id'] for i in indices[0]],\n",
        "        'doc_indices': indices[0].tolist(),\n",
        "        'scores': scores[0].tolist()\n",
        "    }\n",
        "\n",
        "print(f\"\\n✓ Recuperación inicial completada\")\n",
        "print(f\"  Consultas procesadas: {len(initial_results)}\")\n",
        "print(f\"  Documentos por consulta: {k_initial}\")\n",
        "print(f\"  Total de recuperaciones: {len(initial_results) * k_initial:,}\")"
      ],
      "metadata": {
        "id": "1fKypSGblzGg",
        "outputId": "cf5a39e6-7fc9-40f6-deb4-57e9dee8b2d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "RECUPERACIÓN INICIAL (First-Stage Retrieval)\n",
            "================================================================================\n",
            "Recuperando top-100 documentos para cada consulta...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Consultas: 100%|██████████| 10/10 [00:00<00:00, 98.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Recuperación inicial completada\n",
            "  Consultas procesadas: 10\n",
            "  Documentos por consulta: 100\n",
            "  Total de recuperaciones: 1,000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. RE-RANKING DE RESULTADOS\n",
        "Mejoraremos los resultados iniciales con re-ranking:\n",
        "\n",
        "Los Cross-Encoders analizan la relación entre query y documento de forma más profunda\n",
        "Son más lentos pero más precisos que los embeddings\n"
      ],
      "metadata": {
        "id": "JyhNjpUVl4X4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CARGA DE MODELO DE RE-RANKING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"Cargando Cross-Encoder para re-ranking...\")\n",
        "print(\"Modelo: cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
        "\n",
        "reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "\n",
        "print(\"✓ Modelo de re-ranking cargado\")"
      ],
      "metadata": {
        "id": "dkrQBAezl_uE",
        "outputId": "19fc78c5-64b5-494b-89e0-c187514d92ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363,
          "referenced_widgets": [
            "452b1c62c02744f794b19c1049c7dbcf",
            "73b3a62bccc8454a9a21bfd7a8fb4f7d",
            "7484d147ad75467f92bcbe5e10711463",
            "65b35f0b500c4cc5a8d998525482abd0",
            "6db7799925db488e80d12a4cbec8689e",
            "d24b4dfcc95e4620b63284600dd331d0",
            "06d45bf27e5f4f278a3f460fb1b8b2db",
            "629cbfeb4c32410d82bc711b361cbba5",
            "2615d7e611eb452585acd0faf1b5c87b",
            "365b416350f84dcd89f238b2d2fada41",
            "90613b1e3aa64ed9a15da63cd0259197",
            "6adac09069604dbb8cfabb1cec32e88b",
            "03b73a8b33c24a62b265c66a2b16c022",
            "f964078a9cea4d7290f9fe5ea5c643cc",
            "8679e96906fa414b812d6cf2a2444a29",
            "34cc257231f24ca29cf8d4b9f34984ab",
            "73aff62339af4bd2a7a10934de371574",
            "ef952a15e3554dab961a0a5f5a1bf225",
            "4d172b13d1e64b27ae421c8db780784f",
            "f2925074eac34029885091a083d5b3f7",
            "e6d369daf77d4ca89b7c5317986dc88a",
            "8b06c3fc253d47d49e3eaa2428938be3",
            "36939c8fa065475fb8cec433db6b855d",
            "95c395b2afc349bca5f8c8ef2d0af69a",
            "6f73f5541de844e88d95957950c4df0c",
            "237d2ef04e624afa868b93feb37203f9",
            "938f40f756274586aeae6ee8ebc4326b",
            "bd0431cec9c34b048a62450055f3a4bc",
            "bfea2d6f122e444e8b1f95b9e1e9b5f2",
            "74432a4dc49e46cf87b8ca681a2d79c5",
            "a5520fb3a7ef441e80c69face3659780",
            "f5ab4d3a44994d628f1cecff6fa3c2f3",
            "6c282a882d8d444583e32685e25aced7",
            "f091f97dc2724fb7b183aaeb59701198",
            "94c1a990826e479294a3ea3b9a6fc7b4",
            "0cbe111798204734b330511eb903099a",
            "6a1dd07388d94399bf346f4baa7c8df9",
            "fadc61526dc849bc89b6648763ccc717",
            "3e4ea33150db4a5db45d40e92d688519",
            "c2900c5cf98340448f7f8093ed49921e",
            "f6df150ccf4a4c41a153f2b330db063d",
            "ee98f412fd9d4bdfbd84bacde40631fe",
            "908356d13feb4edf901a5c0007fdcf06",
            "d2b352c86cc9427aa5a8c3690b1cd7c9",
            "9500f097581b441f839a2e99c4b38005",
            "28c9bbc768494a32969cd0655128c7db",
            "6f44b2cb2f2342cea6714cd5dd6485bf",
            "088a5e36d47f42ccb123016cd84f5ec7",
            "84985d01fdf34f0f983787f7b1b5b949",
            "a351cd4342ea4ce9aa189c5927445f82",
            "62c3c6458e0746a6aa84c7a042623755",
            "718447f892f24a8283964af591f270e1",
            "b92a5af639d6451a86f69d94c8854087",
            "e75033e6398a42e183325e1488565342",
            "a221e0dff8b5425583f0d482389e75d3",
            "3c73021172cb45dca16d33ff6f2d9ac7",
            "d8701514349549198cdc00ef9be3c963",
            "31186b02ec3942ac891a7200bd5215f1",
            "ec6a1b19a97f4c1aa5cbd3aca188ae82",
            "6c13f7104be9428b9ad59f66485d2814",
            "d3855fcc619b4209bcf453ddc1ab03a0",
            "117acd7914824828aa1ff9a287c7a81a",
            "5ad20d5b0e754ceaa9e4f6734650636f",
            "bb725644ade043fc8a522b84050ef003",
            "fd230f3fc7564204b99ca2d44c0bef84",
            "09ae91980d1b49cb8291e257f506086d",
            "c63c488a44e04768b24c7167d54fab6c",
            "e23c8f23a44341489512c1f49a9f8d00",
            "c4468bc36ecd434b8a55eb2af0933869",
            "86f5c81232d440cd8796bacdd11fd340",
            "3cb162751ef24a3797827db2f02c209d",
            "6a10df6b40cb426a818abcf802c83b2e",
            "b72c7b89080e4df3be5b6c27b36a18ea",
            "afc6edd0bdb148fdaa8d31e0ab32e802",
            "69a8efc2e3bc4622a3390a4317bc4345",
            "bac123868c3e49be93f887d1d566b5dc",
            "809100abf965494eaf991b55dc87e332"
          ]
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "CARGA DE MODELO DE RE-RANKING\n",
            "================================================================================\n",
            "Cargando Cross-Encoder para re-ranking...\n",
            "Modelo: cross-encoder/ms-marco-MiniLM-L-6-v2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "452b1c62c02744f794b19c1049c7dbcf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6adac09069604dbb8cfabb1cec32e88b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36939c8fa065475fb8cec433db6b855d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f091f97dc2724fb7b183aaeb59701198"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9500f097581b441f839a2e99c4b38005"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c73021172cb45dca16d33ff6f2d9ac7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c63c488a44e04768b24c7167d54fab6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Modelo de re-ranking cargado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RE-RANKING DE RESULTADOS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "top_k_final = 20  # Top-k documentos finales\n",
        "final_results = {}\n",
        "\n",
        "print(f\"Re-rankeando top-{k_initial} → top-{top_k_final} para cada consulta...\")\n",
        "\n",
        "for idx, row in tqdm(queries_df.iterrows(), total=len(queries_df), desc=\"Re-ranking\"):\n",
        "    query_id = row['query_id']\n",
        "    query_text = row['full_text']\n",
        "\n",
        "    # Obtener documentos iniciales\n",
        "    initial_doc_ids = initial_results[query_id]['doc_ids']\n",
        "\n",
        "    # Preparar textos de documentos (título + abstract truncado)\n",
        "    doc_texts = []\n",
        "    valid_doc_ids = []\n",
        "\n",
        "    for doc_id in initial_doc_ids:\n",
        "        doc_row = docs_df[docs_df['id'] == doc_id]\n",
        "        if len(doc_row) > 0:\n",
        "            # Truncar a 512 caracteres para el cross-encoder\n",
        "            text = doc_row.iloc[0]['full_text'][:512]\n",
        "            doc_texts.append(text)\n",
        "            valid_doc_ids.append(doc_id)\n",
        "\n",
        "    # Crear pares [query, documento]\n",
        "    pairs = [[query_text[:512], doc_text] for doc_text in doc_texts]\n",
        "\n",
        "    # Obtener scores del cross-encoder\n",
        "    scores = reranker.predict(pairs, show_progress_bar=False)\n",
        "\n",
        "    # Ordenar por score descendente\n",
        "    ranked_indices = np.argsort(scores)[::-1][:top_k_final]\n",
        "\n",
        "    # Guardar resultados re-rankeados\n",
        "    final_results[query_id] = {\n",
        "        'doc_ids': [valid_doc_ids[i] for i in ranked_indices],\n",
        "        'scores': [float(scores[i]) for i in ranked_indices]\n",
        "    }\n",
        "\n",
        "print(f\"\\n✓ Re-ranking completado\")\n",
        "print(f\"  Consultas procesadas: {len(final_results)}\")\n",
        "print(f\"  Documentos finales por consulta: {top_k_final}\")"
      ],
      "metadata": {
        "id": "-41Vg0CumFIT",
        "outputId": "8376211b-1c2b-401b-81ec-ce47b4289dca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "RE-RANKING DE RESULTADOS\n",
            "================================================================================\n",
            "Re-rankeando top-100 → top-20 para cada consulta...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Re-ranking: 100%|██████████| 10/10 [00:05<00:00,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Re-ranking completado\n",
            "  Consultas procesadas: 10\n",
            "  Documentos finales por consulta: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. SIMULACIÓN Y VISUALIZACIÓN DE CONSULTAS\n",
        "Mostraremos los resultados obtenidos:\n",
        "\n",
        "Compararemos resultados antes y después del re-ranking\n",
        "\n",
        "Mostraremos información completa de los papers recuperados\n",
        "\n",
        "Analizaremos la mejora en relevancia con los qrels"
      ],
      "metadata": {
        "id": "Nll-p5jemJCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_results(query_id, n_show=5):\n",
        "    \"\"\"\n",
        "    Muestra resultados de una consulta antes y después del re-ranking\n",
        "    \"\"\"\n",
        "    # Información de la consulta\n",
        "    query_info = queries_df[queries_df['query_id'] == query_id].iloc[0]\n",
        "\n",
        "    print(f\"\\n{'='*100}\")\n",
        "    print(f\"CONSULTA: {query_id}\")\n",
        "    print(f\"{'='*100}\")\n",
        "    print(f\"Título: {query_info['title']}\")\n",
        "    print(f\"Descripción: {query_info['description']}\")\n",
        "    print(f\"{'='*100}\")\n",
        "\n",
        "    # RESULTADOS INICIALES\n",
        "    print(f\"\\n{'─'*100}\")\n",
        "    print(f\"RESULTADOS INICIALES (FAISS) - Top {n_show}\")\n",
        "    print(f\"{'─'*100}\")\n",
        "\n",
        "    initial_doc_ids = initial_results[query_id]['doc_ids'][:n_show]\n",
        "    initial_scores = initial_results[query_id]['scores'][:n_show]\n",
        "\n",
        "    for i, (doc_id, score) in enumerate(zip(initial_doc_ids, initial_scores), 1):\n",
        "        doc = docs_df[docs_df['id'] == doc_id].iloc[0]\n",
        "\n",
        "        print(f\"\\n{i}. [{doc_id}] Score: {score:.4f}\")\n",
        "        print(f\"   Título: {doc['title_clean']}\")\n",
        "        print(f\"   Categorías: {doc['categories']}\")\n",
        "        print(f\"   Abstract: {doc['abstract_clean'][:200]}...\")\n",
        "        print(f\"   URL: https://arxiv.org/abs/{doc_id}\")\n",
        "\n",
        "    # RESULTADOS FINALES (RE-RANKING)\n",
        "    print(f\"\\n{'─'*100}\")\n",
        "    print(f\"RESULTADOS FINALES (Re-ranking) - Top {n_show}\")\n",
        "    print(f\"{'─'*100}\")\n",
        "\n",
        "    final_doc_ids = final_results[query_id]['doc_ids'][:n_show]\n",
        "    final_scores = final_results[query_id]['scores'][:n_show]\n",
        "\n",
        "    for i, (doc_id, score) in enumerate(zip(final_doc_ids, final_scores), 1):\n",
        "        doc = docs_df[docs_df['id'] == doc_id].iloc[0]\n",
        "\n",
        "        print(f\"\\n{i}. [{doc_id}] Score: {score:.4f}\")\n",
        "        print(f\"   Título: {doc['title_clean']}\")\n",
        "        print(f\"   Categorías: {doc['categories']}\")\n",
        "        print(f\"   Abstract: {doc['abstract_clean'][:200]}...\")\n",
        "        print(f\"   URL: https://arxiv.org/abs/{doc_id}\")\n",
        "\n",
        "    # ANÁLISIS DE RELEVANCIA\n",
        "    print(f\"\\n{'─'*100}\")\n",
        "    print(f\"ANÁLISIS DE RELEVANCIA (basado en qrels)\")\n",
        "    print(f\"{'─'*100}\")\n",
        "\n",
        "    # Obtener documentos relevantes según qrels\n",
        "    relevant_docs = qrels_df[\n",
        "        (qrels_df['query_id'] == query_id) &\n",
        "        (qrels_df['relevance'] > 0)\n",
        "    ]['doc_id'].tolist()\n",
        "\n",
        "    initial_top = set(initial_results[query_id]['doc_ids'][:n_show])\n",
        "    final_top = set(final_results[query_id]['doc_ids'][:n_show])\n",
        "\n",
        "    initial_relevant = len(initial_top & set(relevant_docs))\n",
        "    final_relevant = len(final_top & set(relevant_docs))\n",
        "\n",
        "    print(f\"Total de documentos relevantes: {len(relevant_docs)}\")\n",
        "    print(f\"Relevantes en top-{n_show} inicial: {initial_relevant} ({initial_relevant/n_show*100:.1f}%)\")\n",
        "    print(f\"Relevantes en top-{n_show} final: {final_relevant} ({final_relevant/n_show*100:.1f}%)\")\n",
        "\n",
        "    if final_relevant > initial_relevant:\n",
        "        print(f\"✓ Mejora: +{final_relevant - initial_relevant} documentos relevantes\")\n",
        "    elif final_relevant == initial_relevant:\n",
        "        print(f\"= Sin cambio en documentos relevantes\")\n",
        "    else:\n",
        "        print(f\"⚠ Disminución: {final_relevant - initial_relevant} documentos relevantes\")\n",
        "\n",
        "# Mostrar resultados para todas las consultas\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"SIMULACIÓN DE CONSULTAS - RESULTADOS DETALLADOS\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "for query_id in queries_df['query_id']:\n",
        "    display_results(query_id, n_show=5)"
      ],
      "metadata": {
        "id": "Z6Uwe4YWmGOV",
        "outputId": "5fe3f018-ad96-46fc-f1a5-b56e91750f4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "SIMULACIÓN DE CONSULTAS - RESULTADOS DETALLADOS\n",
            "====================================================================================================\n",
            "\n",
            "====================================================================================================\n",
            "CONSULTA: Q001\n",
            "====================================================================================================\n",
            "Título: Deep learning convolutional neural networks\n",
            "Descripción: Papers about deep learning using convolutional neural networks for image processing and computer vision\n",
            "====================================================================================================\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "RESULTADOS INICIALES (FAISS) - Top 5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "1. [0705.2011] Score: 0.8795\n",
            "   Título: Multi-Dimensional Recurrent Neural Networks\n",
            "   Categorías: cs.AI cs.CV\n",
            "   Abstract: Recurrent neural networks (RNNs) have proved effective at one dimensional sequence learning tasks, such as speech and online handwriting recognition. Some of the properties that make RNNs suitable for...\n",
            "   URL: https://arxiv.org/abs/0705.2011\n",
            "\n",
            "2. [0709.3642] Score: 0.8736\n",
            "   Título: Functional Multi-Layer Perceptron: a Nonlinear Tool for Functional Data  Analysis\n",
            "   Categorías: cs.NE\n",
            "   Abstract: In this paper, we study a natural extension of Multi-Layer Perceptrons (MLP) to functional inputs. We show that fundamental results for classical MLP can be extended to functional MLP. We obtain unive...\n",
            "   URL: https://arxiv.org/abs/0709.3642\n",
            "\n",
            "3. [0706.3188] Score: 0.8722\n",
            "   Título: A tutorial on conformal prediction\n",
            "   Categorías: cs.LG stat.ML\n",
            "   Abstract: Conformal prediction uses past experience to determine precise levels of confidence in new predictions. Given an error probability $\\epsilon$, together with a method that makes a prediction $\\hat{y}$ ...\n",
            "   URL: https://arxiv.org/abs/0706.3188\n",
            "\n",
            "4. [0709.3967] Score: 0.8711\n",
            "   Título: Classification of Images Using Support Vector Machines\n",
            "   Categorías: cs.LG cs.AI\n",
            "   Abstract: Support Vector Machines (SVMs) are a relatively new supervised classification technique to the land cover mapping community. They have their roots in Statistical Learning Theory and have gained promin...\n",
            "   URL: https://arxiv.org/abs/0709.3967\n",
            "\n",
            "5. [0708.3900] Score: 0.8699\n",
            "   Título: Inference from correlated patterns: a unified theory for perceptron  learning and linear vector channels\n",
            "   Categorías: cs.IT cond-mat.dis-nn math.IT\n",
            "   Abstract: A framework to analyze inference performance in densely connected single-layer feed-forward networks is developed for situations where a given data set is composed of correlated patterns. The framewor...\n",
            "   URL: https://arxiv.org/abs/0708.3900\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "RESULTADOS FINALES (Re-ranking) - Top 5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "1. [0707.0930] Score: -1.4344\n",
            "   Título: Bayesian Learning of Neural Networks for Signal/Background  Discrimination in Particle Physics\n",
            "   Categorías: physics.data-an\n",
            "   Abstract: Neural networks are used extensively in classification problems in particle physics research. Since the training of neural networks can be viewed as a problem of inference, Bayesian learning of neural...\n",
            "   URL: https://arxiv.org/abs/0707.0930\n",
            "\n",
            "2. [0707.4524] Score: -1.5558\n",
            "   Título: Image Authentication Based on Neural Networks\n",
            "   Categorías: cs.MM cs.NE\n",
            "   Abstract: Neural network has been attracting more and more researchers since the past decades. The properties, such as parameter sensitivity, random similarity, learning ability, etc., make it suitable for info...\n",
            "   URL: https://arxiv.org/abs/0707.4524\n",
            "\n",
            "3. [0706.1419] Score: -1.9163\n",
            "   Título: Regularization by free additive convolution, square and rectangular  cases\n",
            "   Categorías: math.PR\n",
            "   Abstract: The free convolution is the binary operation on the set of probability measures on the real line which allows to deduce, from the individual spectral distributions, the spectral distribution of a sum ...\n",
            "   URL: https://arxiv.org/abs/0706.1419\n",
            "\n",
            "4. [0705.2011] Score: -1.9566\n",
            "   Título: Multi-Dimensional Recurrent Neural Networks\n",
            "   Categorías: cs.AI cs.CV\n",
            "   Abstract: Recurrent neural networks (RNNs) have proved effective at one dimensional sequence learning tasks, such as speech and online handwriting recognition. Some of the properties that make RNNs suitable for...\n",
            "   URL: https://arxiv.org/abs/0705.2011\n",
            "\n",
            "5. [0705.2301] Score: -2.2859\n",
            "   Título: Withrawn paper\n",
            "   Categorías: gr-qc astro-ph hep-th\n",
            "   Abstract: This paper has been withdrawn by the authors due to some fatal errors in the analysis....\n",
            "   URL: https://arxiv.org/abs/0705.2301\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "ANÁLISIS DE RELEVANCIA (basado en qrels)\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Total de documentos relevantes: 50\n",
            "Relevantes en top-5 inicial: 2 (40.0%)\n",
            "Relevantes en top-5 final: 3 (60.0%)\n",
            "✓ Mejora: +1 documentos relevantes\n",
            "\n",
            "====================================================================================================\n",
            "CONSULTA: Q002\n",
            "====================================================================================================\n",
            "Título: Natural language processing transformer models\n",
            "Descripción: Research on transformer-based models for natural language understanding\n",
            "====================================================================================================\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "RESULTADOS INICIALES (FAISS) - Top 5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "1. [0709.2401] Score: 0.8283\n",
            "   Título: Bootstrapping Deep Lexical Resources: Resources for Courses\n",
            "   Categorías: cs.CL\n",
            "   Abstract: We propose a range of deep lexical acquisition methods which make use of morphological, syntactic and ontological language resources to model word similarity and bootstrap from a seed lexicon. The dif...\n",
            "   URL: https://arxiv.org/abs/0709.2401\n",
            "\n",
            "2. [0707.3269] Score: 0.8277\n",
            "   Título: International Standard for a Linguistic Annotation Framework\n",
            "   Categorías: cs.CL\n",
            "   Abstract: This paper describes the Linguistic Annotation Framework under development within ISO TC37 SC4 WG1. The Linguistic Annotation Framework is intended to serve as a basis for harmonizing existing languag...\n",
            "   URL: https://arxiv.org/abs/0707.3269\n",
            "\n",
            "3. [0710.0105] Score: 0.8235\n",
            "   Título: Zipf's Law and Avoidance of Excessive Synonymy\n",
            "   Categorías: cs.CL physics.soc-ph\n",
            "   Abstract: Zipf's law states that if words of language are ranked in the order of decreasing frequency in texts, the frequency of a word is inversely proportional to its rank. It is very robust as an experimenta...\n",
            "   URL: https://arxiv.org/abs/0710.0105\n",
            "\n",
            "4. [0706.1068] Score: 0.8162\n",
            "   Título: Rota-Baxter Categories\n",
            "   Categorías: math.CT math.CO\n",
            "   Abstract: We introduce Rota-Baxter categories and construct examples of such structures....\n",
            "   URL: https://arxiv.org/abs/0706.1068\n",
            "\n",
            "5. [0709.1207] Score: 0.8152\n",
            "   Título: The P versus NP Brief\n",
            "   Categorías: cs.CC\n",
            "   Abstract: This paper discusses why P and NP are likely to be different. It analyses the essence of the concepts and points out that P and NP might be diverse by sheer definition. It also speculates that P and N...\n",
            "   URL: https://arxiv.org/abs/0709.1207\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "RESULTADOS FINALES (Re-ranking) - Top 5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "1. [0707.3559] Score: -0.2323\n",
            "   Título: Practical Approach to Knowledge-based Question Answering with Natural  Language Understanding and Advanced Reasoning\n",
            "   Categorías: cs.CL cs.AI cs.HC cs.IR\n",
            "   Abstract: This research hypothesized that a practical approach in the form of a solution framework known as Natural Language Understanding and Reasoning for Intelligence (NaLURI), which combines full-discourse ...\n",
            "   URL: https://arxiv.org/abs/0707.3559\n",
            "\n",
            "2. [0710.2523] Score: -4.2009\n",
            "   Título: An analysis of the abstracts presented at the annual meetings of the  Society for Neuroscience from 2001 to 2006\n",
            "   Categorías: physics.data-an q-bio.NC\n",
            "   Abstract: We extracted and processed abstract data from the SFN annual meeting abstracts during the period 2001-2006, using techniques and software from natural language processing, database management, and dat...\n",
            "   URL: https://arxiv.org/abs/0710.2523\n",
            "\n",
            "3. [0707.3270] Score: -5.2329\n",
            "   Título: A Formal Model of Dictionary Structure and Content\n",
            "   Categorías: cs.CL\n",
            "   Abstract: We show that a general model of lexical information conforms to an abstract model that reflects the hierarchy of information found in a typical dictionary entry. We show that this model can be mapped ...\n",
            "   URL: https://arxiv.org/abs/0707.3270\n",
            "\n",
            "4. [0709.3045] Score: -5.2334\n",
            "   Título: Network model of human language\n",
            "   Categorías: physics.soc-ph physics.comp-ph\n",
            "   Abstract: The phenomenon of human language is widely studied from various points of view. It is interesting not only for social scientists, antropologists or philosophers, but also for those, interesting in the...\n",
            "   URL: https://arxiv.org/abs/0709.3045\n",
            "\n",
            "5. [0704.3886] Score: -5.7150\n",
            "   Título: A Note on Ontology and Ordinary Language\n",
            "   Categorías: cs.AI cs.CL\n",
            "   Abstract: We argue for a compositional semantics grounded in a strongly typed ontology that reflects our commonsense view of the world and the way we talk about it. Assuming such a structure we show that the se...\n",
            "   URL: https://arxiv.org/abs/0704.3886\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "ANÁLISIS DE RELEVANCIA (basado en qrels)\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Total de documentos relevantes: 41\n",
            "Relevantes en top-5 inicial: 0 (0.0%)\n",
            "Relevantes en top-5 final: 2 (40.0%)\n",
            "✓ Mejora: +2 documentos relevantes\n",
            "\n",
            "====================================================================================================\n",
            "CONSULTA: Q003\n",
            "====================================================================================================\n",
            "Título: Reinforcement learning algorithms\n",
            "Descripción: Papers on reinforcement learning methods and applications\n",
            "====================================================================================================\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "RESULTADOS INICIALES (FAISS) - Top 5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "1. [0707.3087] Score: 0.8949\n",
            "   Título: Universal Reinforcement Learning\n",
            "   Categorías: cs.IT cs.LG math.IT\n",
            "   Abstract: We consider an agent interacting with an unmodeled environment. At each time, the agent makes an observation, takes an action, and incurs a cost. Its actions can influence future observations and cost...\n",
            "   URL: https://arxiv.org/abs/0707.3087\n",
            "\n",
            "2. [0707.1295] Score: 0.8398\n",
            "   Título: Efficient supervised learning in networks with binary synapses\n",
            "   Categorías: q-bio.NC cond-mat.stat-mech cs.NE q-bio.QM\n",
            "   Abstract: Recent experimental studies indicate that synaptic changes induced by neuronal activity are discrete jumps between a small number of stable states. Learning in systems with discrete synapses is known ...\n",
            "   URL: https://arxiv.org/abs/0707.1295\n",
            "\n",
            "3. [0708.2377] Score: 0.8392\n",
            "   Título: Online Learning in Discrete Hidden Markov Models\n",
            "   Categorías: stat.ML\n",
            "   Abstract: We present and analyse three online algorithms for learning in discrete Hidden Markov Models (HMMs) and compare them with the Baldi-Chauvin Algorithm. Using the Kullback-Leibler divergence as a measur...\n",
            "   URL: https://arxiv.org/abs/0708.2377\n",
            "\n",
            "4. [0709.1948] Score: 0.8386\n",
            "   Título: Information theoretic approach to interactive learning\n",
            "   Categorías: physics.data-an physics.bio-ph\n",
            "   Abstract: The principles of statistical mechanics and information theory play an important role in learning and have inspired both theory and the design of numerous machine learning algorithms. The new aspect i...\n",
            "   URL: https://arxiv.org/abs/0709.1948\n",
            "\n",
            "5. [0704.3780] Score: 0.8359\n",
            "   Título: Stochastic Optimization Algorithms\n",
            "   Categorías: cs.NE\n",
            "   Abstract: When looking for a solution, deterministic methods have the enormous advantage that they do find global optima. Unfortunately, they are very CPU-intensive, and are useless on untractable NP-hard probl...\n",
            "   URL: https://arxiv.org/abs/0704.3780\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "RESULTADOS FINALES (Re-ranking) - Top 5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "1. [0707.3087] Score: -1.4055\n",
            "   Título: Universal Reinforcement Learning\n",
            "   Categorías: cs.IT cs.LG math.IT\n",
            "   Abstract: We consider an agent interacting with an unmodeled environment. At each time, the agent makes an observation, takes an action, and incurs a cost. Its actions can influence future observations and cost...\n",
            "   URL: https://arxiv.org/abs/0707.3087\n",
            "\n",
            "2. [0707.0303] Score: -2.8258\n",
            "   Título: Learning from dependent observations\n",
            "   Categorías: stat.ML stat.ME\n",
            "   Abstract: In most papers establishing consistency for learning algorithms it is assumed that the observations used for training are realizations of an i.i.d. process. In this paper we go far beyond this classic...\n",
            "   URL: https://arxiv.org/abs/0707.0303\n",
            "\n",
            "3. [0706.0280] Score: -2.8656\n",
            "   Título: Multi-Agent Modeling Using Intelligent Agents in the Game of Lerpa\n",
            "   Categorías: cs.MA cs.GT\n",
            "   Abstract: Game theory has many limitations implicit in its application. By utilizing multiagent modeling, it is possible to solve a number of problems that are unsolvable using traditional game theory. In this ...\n",
            "   URL: https://arxiv.org/abs/0706.0280\n",
            "\n",
            "4. [0706.1317] Score: -3.1621\n",
            "   Título: A model for learning to segment temporal sequences, utilizing a mixture  of RNN experts together with adaptive variance\n",
            "   Categorías: nlin.AO\n",
            "   Abstract: This paper proposes a novel learning method for a mixture of recurrent neural network (RNN) experts model, which can acquire the ability to generate desired sequences by dynamically switching between ...\n",
            "   URL: https://arxiv.org/abs/0706.1317\n",
            "\n",
            "5. [0708.2707] Score: -3.3392\n",
            "   Título: Learning and innovative elements of strategy adoption rules expand  cooperative network topologies\n",
            "   Categorías: q-bio.MN cond-mat.dis-nn nlin.AO physics.bio-ph\n",
            "   Abstract: Cooperation plays a key role in the evolution of complex systems. However, the level of cooperation extensively varies with the topology of agent networks in the widely used models of repeated games. ...\n",
            "   URL: https://arxiv.org/abs/0708.2707\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "ANÁLISIS DE RELEVANCIA (basado en qrels)\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Total de documentos relevantes: 66\n",
            "Relevantes en top-5 inicial: 1 (20.0%)\n",
            "Relevantes en top-5 final: 2 (40.0%)\n",
            "✓ Mejora: +1 documentos relevantes\n",
            "\n",
            "====================================================================================================\n",
            "CONSULTA: Q004\n",
            "====================================================================================================\n",
            "Título: Graph neural networks\n",
            "Descripción: Graph-based deep learning and neural network architectures\n",
            "====================================================================================================\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "RESULTADOS INICIALES (FAISS) - Top 5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "1. [0706.1835] Score: 0.8745\n",
            "   Título: General concepts of graphs\n",
            "   Categorías: math.CT\n",
            "   Abstract: A little general abstract combinatorial nonsense delivered in this note is a presentation of some old and basic concepts, central to discrete mathematics, in terms of new words. The treatment is from ...\n",
            "   URL: https://arxiv.org/abs/0706.1835\n",
            "\n",
            "2. [0708.3900] Score: 0.8343\n",
            "   Título: Inference from correlated patterns: a unified theory for perceptron  learning and linear vector channels\n",
            "   Categorías: cs.IT cond-mat.dis-nn math.IT\n",
            "   Abstract: A framework to analyze inference performance in densely connected single-layer feed-forward networks is developed for situations where a given data set is composed of correlated patterns. The framewor...\n",
            "   URL: https://arxiv.org/abs/0708.3900\n",
            "\n",
            "3. [0705.0599] Score: 0.8320\n",
            "   Título: NodeTrix: Hybrid Representation for Analyzing Social Networks\n",
            "   Categorías: cs.HC\n",
            "   Abstract: The need to visualize large social networks is growing as hardware capabilities make analyzing large networks feasible and many new data sets become available. Unfortunately, the visualizations in exi...\n",
            "   URL: https://arxiv.org/abs/0705.0599\n",
            "\n",
            "4. [0704.3821] Score: 0.8285\n",
            "   Título: Compositions of Graphs Revisited\n",
            "   Categorías: math.CO\n",
            "   Abstract: The idea of graph compositions, which was introduced by A. Knopfmacher and M. E. Mays, generalizes both ordinary compositions of positive integers and partitions of finite sets. In their original pape...\n",
            "   URL: https://arxiv.org/abs/0704.3821\n",
            "\n",
            "5. [0706.0113] Score: 0.8283\n",
            "   Título: Graph spectra as a systematic tool in computational biology\n",
            "   Categorías: nlin.AO q-bio.QM\n",
            "   Abstract: We present the spectrum of the (normalized) graph Laplacian as a systematic tool for the investigation of networks, and we describe basic properties of eigenvalues and eigenfunctions. Processes of gra...\n",
            "   URL: https://arxiv.org/abs/0706.0113\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "RESULTADOS FINALES (Re-ranking) - Top 5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "1. [0705.2011] Score: -2.7072\n",
            "   Título: Multi-Dimensional Recurrent Neural Networks\n",
            "   Categorías: cs.AI cs.CV\n",
            "   Abstract: Recurrent neural networks (RNNs) have proved effective at one dimensional sequence learning tasks, such as speech and online handwriting recognition. Some of the properties that make RNNs suitable for...\n",
            "   URL: https://arxiv.org/abs/0705.2011\n",
            "\n",
            "2. [0705.2301] Score: -4.6821\n",
            "   Título: Withrawn paper\n",
            "   Categorías: gr-qc astro-ph hep-th\n",
            "   Abstract: This paper has been withdrawn by the authors due to some fatal errors in the analysis....\n",
            "   URL: https://arxiv.org/abs/0705.2301\n",
            "\n",
            "3. [0704.3702] Score: -5.1941\n",
            "   Título: Statistical mechanics of complex networks\n",
            "   Categorías: cond-mat.stat-mech\n",
            "   Abstract: The science of complex networks is a new interdisciplinary branch of science which has arisen recently on the interface of physics, biology, social and computer sciences, and others. Its main goal is ...\n",
            "   URL: https://arxiv.org/abs/0704.3702\n",
            "\n",
            "4. [0706.0113] Score: -5.2763\n",
            "   Título: Graph spectra as a systematic tool in computational biology\n",
            "   Categorías: nlin.AO q-bio.QM\n",
            "   Abstract: We present the spectrum of the (normalized) graph Laplacian as a systematic tool for the investigation of networks, and we describe basic properties of eigenvalues and eigenfunctions. Processes of gra...\n",
            "   URL: https://arxiv.org/abs/0706.0113\n",
            "\n",
            "5. [0705.3215] Score: -5.4010\n",
            "   Título: On Automorphism Groups of Networks\n",
            "   Categorías: physics.soc-ph math.CO\n",
            "   Abstract: We consider the size and structure of the automorphism groups of a variety of empirical `real-world' networks and find that, in contrast to classical random graph models, many real-world networks are ...\n",
            "   URL: https://arxiv.org/abs/0705.3215\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "ANÁLISIS DE RELEVANCIA (basado en qrels)\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Total de documentos relevantes: 18\n",
            "Relevantes en top-5 inicial: 0 (0.0%)\n",
            "Relevantes en top-5 final: 0 (0.0%)\n",
            "= Sin cambio en documentos relevantes\n",
            "\n",
            "====================================================================================================\n",
            "CONSULTA: Q005\n",
            "====================================================================================================\n",
            "Título: Quantum computing algorithms\n",
            "Descripción: Quantum algorithms and quantum information processing\n",
            "====================================================================================================\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "RESULTADOS INICIALES (FAISS) - Top 5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "1. [0708.0261] Score: 0.9655\n",
            "   Título: An Introduction to Quantum Computing\n",
            "   Categorías: quant-ph\n",
            "   Abstract: Quantum Computing is a new and exciting field at the intersection of mathematics, computer science and physics. It concerns a utilization of quantum mechanics to improve the efficiency of computation....\n",
            "   URL: https://arxiv.org/abs/0708.0261\n",
            "\n",
            "2. [0705.4193] Score: 0.9297\n",
            "   Título: Lecture notes on Optical Quantum Computing\n",
            "   Categorías: quant-ph\n",
            "   Abstract: A quantum computer is a machine that can perform certain calculations much faster than a classical computer by using the laws of quantum mechanics. Quantum computers do not exist yet, because it is ex...\n",
            "   URL: https://arxiv.org/abs/0705.4193\n",
            "\n",
            "3. [0708.3751] Score: 0.9084\n",
            "   Título: Errors and paradoxes in quantum mechanics\n",
            "   Categorías: quant-ph\n",
            "   Abstract: Errors and paradoxes in quantum mechanics, entry in the Compendium of Quantum Physics: Concepts, Experiments, History and Philosophy, ed. F. Weinert, K. Hentschel, D. Greenberger and B. Falkenburg (Sp...\n",
            "   URL: https://arxiv.org/abs/0708.3751\n",
            "\n",
            "4. [0709.0948] Score: 0.9079\n",
            "   Título: QUBIT4MATLAB V3.0: A program package for quantum information science and  quantum optics for MATLAB\n",
            "   Categorías: quant-ph\n",
            "   Abstract: A program package for MATLAB is introduced that helps calculations in quantum information science and quantum optics. It has commands for the following operations: (i) Reordering the qudits of a quant...\n",
            "   URL: https://arxiv.org/abs/0709.0948\n",
            "\n",
            "5. [0710.1744] Score: 0.9055\n",
            "   Título: Quantum problem solving as simultaneous computation\n",
            "   Categorías: quant-ph\n",
            "   Abstract: I provide an alternative way of seeing quantum computation. First, I describe an idealized classical problem solving machine that, thanks to a many body interaction, reversibly and nondeterministicall...\n",
            "   URL: https://arxiv.org/abs/0710.1744\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "RESULTADOS FINALES (Re-ranking) - Top 5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "1. [0705.4171] Score: 4.0520\n",
            "   Título: Grover search algorithm\n",
            "   Categorías: cs.DS\n",
            "   Abstract: A quantum algorithm is a set of instructions for a quantum computer, however, unlike algorithms in classical computer science their results cannot be guaranteed. A quantum system can undergo two types...\n",
            "   URL: https://arxiv.org/abs/0705.4171\n",
            "\n",
            "2. [0705.3360] Score: 3.1210\n",
            "   Título: The Road to Quantum Artificial Intelligence\n",
            "   Categorías: cs.AI\n",
            "   Abstract: This paper overviews the basic principles and recent advances in the emerging field of Quantum Computation (QC), highlighting its potential application to Artificial Intelligence (AI). The paper provi...\n",
            "   URL: https://arxiv.org/abs/0705.3360\n",
            "\n",
            "3. [0707.1119] Score: 2.6556\n",
            "   Título: Globally controlled fault tolerant quantum computation\n",
            "   Categorías: quant-ph\n",
            "   Abstract: We describe a method to execute globally controlled quantum information processing which admits a fault tolerant quantum error correction scheme. Our scheme nominally uses three species of addressable...\n",
            "   URL: https://arxiv.org/abs/0707.1119\n",
            "\n",
            "4. [0705.2784] Score: 2.6308\n",
            "   Título: Quantum algorithms for hidden nonlinear structures\n",
            "   Categorías: quant-ph\n",
            "   Abstract: Attempts to find new quantum algorithms that outperform classical computation have focused primarily on the nonabelian hidden subgroup problem, which generalizes the central problem solved by Shor's f...\n",
            "   URL: https://arxiv.org/abs/0705.2784\n",
            "\n",
            "5. [0706.0304] Score: 2.4338\n",
            "   Título: Efficient quantum circuit implementation of quantum walks\n",
            "   Categorías: quant-ph\n",
            "   Abstract: Quantum walks, being the quantum analogue of classical random walks, are expected to provide a fruitful source of quantum algorithms. A few such algorithms have already been developed, including the `...\n",
            "   URL: https://arxiv.org/abs/0706.0304\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "ANÁLISIS DE RELEVANCIA (basado en qrels)\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Total de documentos relevantes: 1449\n",
            "Relevantes en top-5 inicial: 5 (100.0%)\n",
            "Relevantes en top-5 final: 4 (80.0%)\n",
            "⚠ Disminución: -1 documentos relevantes\n",
            "\n",
            "====================================================================================================\n",
            "CONSULTA: Q006\n",
            "====================================================================================================\n",
            "Título: Generative adversarial networks\n",
            "Descripción: GAN architectures and applications for generative modeling\n",
            "====================================================================================================\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "RESULTADOS INICIALES (FAISS) - Top 5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "1. [0707.4081] Score: 0.8317\n",
            "   Título: Geometrical derivation of the Boltzmann factor\n",
            "   Categorías: nlin.CD cond-mat.stat-mech cs.MA physics.soc-ph\n",
            "   Abstract: We show that the Boltzmann factor has a geometrical origin. Its derivation follows from the microcanonical picture. The Maxwell-Boltzmann distribution or the wealth distribution in human society are s...\n",
            "   URL: https://arxiv.org/abs/0707.4081\n",
            "\n",
            "2. [0709.0178] Score: 0.8307\n",
            "   Título: Effective Generation of Subjectively Random Binary Sequences\n",
            "   Categorías: cs.HC cs.AI\n",
            "   Abstract: We present an algorithm for effectively generating binary sequences which would be rated by people as highly likely to have been generated by a random process, such as flipping a fair coin....\n",
            "   URL: https://arxiv.org/abs/0709.0178\n",
            "\n",
            "3. [0705.1287] Score: 0.8185\n",
            "   Título: Uniform random sampling of planar graphs in linear time\n",
            "   Categorías: math.CO\n",
            "   Abstract: This article introduces new algorithms for the uniform random generation of labelled planar graphs. Its principles rely on Boltzmann samplers, as recently developed by Duchon, Flajolet, Louchard, and ...\n",
            "   URL: https://arxiv.org/abs/0705.1287\n",
            "\n",
            "4. [0710.2667] Score: 0.8170\n",
            "   Título: On the generalized Jacobi equation\n",
            "   Categorías: gr-qc\n",
            "   Abstract: The standard text-book Jacobi equation (equation of geodesic deviation) arises by linearizing the geodesic equation around some chosen geodesic, where the linearization is done with respect to the coo...\n",
            "   URL: https://arxiv.org/abs/0710.2667\n",
            "\n",
            "5. [0708.1071] Score: 0.8149\n",
            "   Título: Statistical thinking: From Tukey to Vardi and beyond\n",
            "   Categorías: math.ST stat.TH\n",
            "   Abstract: Data miners (minors?) and neural networkers tend to eschew modelling, misled perhaps by misinterpretation of strongly expressed views of John Tukey. I discuss Vardi's views of these issues as well as ...\n",
            "   URL: https://arxiv.org/abs/0708.1071\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "RESULTADOS FINALES (Re-ranking) - Top 5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "1. [0709.1858] Score: -6.5199\n",
            "   Título: Adaptive Coevolutionary Networks: A Review\n",
            "   Categorías: physics.soc-ph cond-mat.stat-mech q-bio.PE\n",
            "   Abstract: Adaptive networks appear in many biological applications. They combine topological evolution of the network with dynamics in the network nodes. Recently, the dynamics of adaptive networks has been inv...\n",
            "   URL: https://arxiv.org/abs/0709.1858\n",
            "\n",
            "2. [0704.3259] Score: -6.5264\n",
            "   Título: Python Unleashed on Systems Biology\n",
            "   Categorías: q-bio.QM q-bio.MN\n",
            "   Abstract: We have built an open-source software system for the modeling of biomolecular reaction networks, SloppyCell, which is written in Python and makes substantial use of third-party libraries for numerics,...\n",
            "   URL: https://arxiv.org/abs/0704.3259\n",
            "\n",
            "3. [0707.3783] Score: -7.0322\n",
            "   Título: Network Rewiring Models\n",
            "   Categorías: cond-mat.stat-mech\n",
            "   Abstract: Recently we showed that a simple model of network rewiring could be solved exactly for any time and any parameter value. We also showed that this model can be recast in terms of several well known mod...\n",
            "   URL: https://arxiv.org/abs/0707.3783\n",
            "\n",
            "4. [0708.1130] Score: -7.4200\n",
            "   Título: Complex Datasets and Inverse Problems. Tomography, Networks and Beyond\n",
            "   Categorías: math.ST stat.TH\n",
            "   Abstract: This book is a collection of papers dedicated to the memory of Yehuda Vardi. Yehuda was the chair of the Department of Statistics of Rutgers University when he passed away unexpectedly on January 13, ...\n",
            "   URL: https://arxiv.org/abs/0708.1130\n",
            "\n",
            "5. [0705.2328] Score: -7.8350\n",
            "   Título: On the realignment criterion and beyond\n",
            "   Categorías: quant-ph\n",
            "   Abstract: The content of this paper is now available as part of arXiv:0802.2019...\n",
            "   URL: https://arxiv.org/abs/0705.2328\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "ANÁLISIS DE RELEVANCIA (basado en qrels)\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Total de documentos relevantes: 13\n",
            "Relevantes en top-5 inicial: 0 (0.0%)\n",
            "Relevantes en top-5 final: 0 (0.0%)\n",
            "= Sin cambio en documentos relevantes\n",
            "\n",
            "====================================================================================================\n",
            "CONSULTA: Q007\n",
            "====================================================================================================\n",
            "Título: Transfer learning domain adaptation\n",
            "Descripción: Transfer learning methods and domain adaptation techniques\n",
            "====================================================================================================\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "RESULTADOS INICIALES (FAISS) - Top 5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "1. [0709.3965] Score: 0.8782\n",
            "   Título: Evolving Classifiers: Methods for Incremental Learning\n",
            "   Categorías: cs.LG cs.AI cs.NE\n",
            "   Abstract: The ability of a classifier to take on new information and classes by evolving the classifier without it having to be fully retrained is known as incremental learning. Incremental learning has been su...\n",
            "   URL: https://arxiv.org/abs/0709.3965\n",
            "\n",
            "2. [0707.0701] Score: 0.8696\n",
            "   Título: Clustering and Feature Selection using Sparse Principal Component  Analysis\n",
            "   Categorías: cs.AI cs.LG cs.MS\n",
            "   Abstract: In this paper, we study the application of sparse principal component analysis (PCA) to clustering and feature selection problems. Sparse PCA seeks sparse factors, or linear combinations of the data v...\n",
            "   URL: https://arxiv.org/abs/0707.0701\n",
            "\n",
            "3. [0708.3779] Score: 0.8663\n",
            "   Título: Comment: Fisher Lecture: Dimension Reduction in Regression\n",
            "   Categorías: stat.ME\n",
            "   Abstract: Comment: Fisher Lecture: Dimension Reduction in Regression [arXiv:0708.3774]...\n",
            "   URL: https://arxiv.org/abs/0708.3779\n",
            "\n",
            "4. [0708.3777] Score: 0.8663\n",
            "   Título: Comment: Fisher Lecture: Dimension Reduction in Regression\n",
            "   Categorías: stat.ME\n",
            "   Abstract: Comment: Fisher Lecture: Dimension Reduction in Regression [arXiv:0708.3774]...\n",
            "   URL: https://arxiv.org/abs/0708.3777\n",
            "\n",
            "5. [0708.3776] Score: 0.8663\n",
            "   Título: Comment: Fisher Lecture: Dimension Reduction in Regression\n",
            "   Categorías: stat.ME\n",
            "   Abstract: Comment: Fisher Lecture: Dimension Reduction in Regression [arXiv:0708.3774]...\n",
            "   URL: https://arxiv.org/abs/0708.3776\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "RESULTADOS FINALES (Re-ranking) - Top 5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "1. [0704.1854] Score: -1.7790\n",
            "   Título: Teaching for transfer\n",
            "   Categorías: physics.ed-ph\n",
            "   Abstract: Students, after they leave our care, are called to solve the diverse problems of the world, so we should teach to increase transfer: the ability to apply fundamental principles to new problems and con...\n",
            "   URL: https://arxiv.org/abs/0704.1854\n",
            "\n",
            "2. [0705.2328] Score: -5.4386\n",
            "   Título: On the realignment criterion and beyond\n",
            "   Categorías: quant-ph\n",
            "   Abstract: The content of this paper is now available as part of arXiv:0802.2019...\n",
            "   URL: https://arxiv.org/abs/0705.2328\n",
            "\n",
            "3. [0709.1948] Score: -5.4885\n",
            "   Título: Information theoretic approach to interactive learning\n",
            "   Categorías: physics.data-an physics.bio-ph\n",
            "   Abstract: The principles of statistical mechanics and information theory play an important role in learning and have inspired both theory and the design of numerous machine learning algorithms. The new aspect i...\n",
            "   URL: https://arxiv.org/abs/0709.1948\n",
            "\n",
            "4. [0709.3965] Score: -5.5914\n",
            "   Título: Evolving Classifiers: Methods for Incremental Learning\n",
            "   Categorías: cs.LG cs.AI cs.NE\n",
            "   Abstract: The ability of a classifier to take on new information and classes by evolving the classifier without it having to be fully retrained is known as incremental learning. Incremental learning has been su...\n",
            "   URL: https://arxiv.org/abs/0709.3965\n",
            "\n",
            "5. [0706.1068] Score: -6.1631\n",
            "   Título: Rota-Baxter Categories\n",
            "   Categorías: math.CT math.CO\n",
            "   Abstract: We introduce Rota-Baxter categories and construct examples of such structures....\n",
            "   URL: https://arxiv.org/abs/0706.1068\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "ANÁLISIS DE RELEVANCIA (basado en qrels)\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Total de documentos relevantes: 18\n",
            "Relevantes en top-5 inicial: 2 (40.0%)\n",
            "Relevantes en top-5 final: 1 (20.0%)\n",
            "⚠ Disminución: -1 documentos relevantes\n",
            "\n",
            "====================================================================================================\n",
            "CONSULTA: Q008\n",
            "====================================================================================================\n",
            "Título: Time series forecasting\n",
            "Descripción: Methods for time series prediction and forecasting\n",
            "====================================================================================================\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "RESULTADOS INICIALES (FAISS) - Top 5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "1. [0709.1504] Score: 0.9282\n",
            "   Título: Maximum Entropy, Time Series and Statistical Inference\n",
            "   Categorías: physics.data-an\n",
            "   Abstract: A brief discussion is given of the traditional version of the Maximum Entropy Method, including a review of some of the criticism that has been made in regard to its use in statistical inference. Moti...\n",
            "   URL: https://arxiv.org/abs/0709.1504\n",
            "\n",
            "2. [0706.3443] Score: 0.9255\n",
            "   Título: The SSM Toolbox for Matlab\n",
            "   Categorías: stat.CO stat.AP\n",
            "   Abstract: State Space Models (SSM) is a MATLAB 7.0 software toolbox for doing time series analysis by state space methods. The software features fully interactive construction and combination of models, with su...\n",
            "   URL: https://arxiv.org/abs/0706.3443\n",
            "\n",
            "3. [0706.4190] Score: 0.9228\n",
            "   Título: SiZer for time series: A new approach to the analysis of trends\n",
            "   Categorías: stat.ME\n",
            "   Abstract: Smoothing methods and SiZer are a useful statistical tool for discovering statistically significant structure in data. Based on scale space ideas originally developed in the computer vision literature...\n",
            "   URL: https://arxiv.org/abs/0706.4190\n",
            "\n",
            "4. [0709.0281] Score: 0.9163\n",
            "   Título: Detrended Cross-Correlation Analysis: A New Method for Analyzing Two  Non-stationary Time Series\n",
            "   Categorías: q-fin.ST cond-mat.stat-mech\n",
            "   Abstract: Here we propose a method, based on detrended covariance which we call detrended cross-correlation analysis (DXA), to investigate power-law cross-correlations between different simultaneously-recorded ...\n",
            "   URL: https://arxiv.org/abs/0709.0281\n",
            "\n",
            "5. [0704.1738] Score: 0.9145\n",
            "   Título: Financial time-series analysis: A brief overview\n",
            "   Categorías: q-fin.ST physics.soc-ph\n",
            "   Abstract: Prices of commodities or assets produce what is called time-series. Different kinds of financial time-series have been recorded and studied for decades. Nowadays, all transactions on a financial marke...\n",
            "   URL: https://arxiv.org/abs/0704.1738\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "RESULTADOS FINALES (Re-ranking) - Top 5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "1. [0709.3418] Score: 2.7215\n",
            "   Título: Spartan Random Processes in Time Series Modeling\n",
            "   Categorías: physics.soc-ph physics.data-an\n",
            "   Abstract: A Spartan random process (SRP) is used to estimate the correlation structure of time series and to predict (extrapolate) the data values. SRP's are motivated from statistical physics, and they can be ...\n",
            "   URL: https://arxiv.org/abs/0709.3418\n",
            "\n",
            "2. [0708.2373] Score: 1.9604\n",
            "   Título: Accumulated prediction errors, information criteria and optimal  forecasting for autoregressive time series\n",
            "   Categorías: math.ST stat.TH\n",
            "   Abstract: The predictive capability of a modification of Rissanen's accumulated prediction error (APE) criterion, APE$_{\\delta_n}$, is investigated in infinite-order autoregressive (AR($\\infty$)) models. Instea...\n",
            "   URL: https://arxiv.org/abs/0708.2373\n",
            "\n",
            "3. [0704.1738] Score: 1.8240\n",
            "   Título: Financial time-series analysis: A brief overview\n",
            "   Categorías: q-fin.ST physics.soc-ph\n",
            "   Abstract: Prices of commodities or assets produce what is called time-series. Different kinds of financial time-series have been recorded and studied for decades. Nowadays, all transactions on a financial marke...\n",
            "   URL: https://arxiv.org/abs/0704.1738\n",
            "\n",
            "4. [0709.0281] Score: 1.4638\n",
            "   Título: Detrended Cross-Correlation Analysis: A New Method for Analyzing Two  Non-stationary Time Series\n",
            "   Categorías: q-fin.ST cond-mat.stat-mech\n",
            "   Abstract: Here we propose a method, based on detrended covariance which we call detrended cross-correlation analysis (DXA), to investigate power-law cross-correlations between different simultaneously-recorded ...\n",
            "   URL: https://arxiv.org/abs/0709.0281\n",
            "\n",
            "5. [0706.3443] Score: 1.4085\n",
            "   Título: The SSM Toolbox for Matlab\n",
            "   Categorías: stat.CO stat.AP\n",
            "   Abstract: State Space Models (SSM) is a MATLAB 7.0 software toolbox for doing time series analysis by state space methods. The software features fully interactive construction and combination of models, with su...\n",
            "   URL: https://arxiv.org/abs/0706.3443\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "ANÁLISIS DE RELEVANCIA (basado en qrels)\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Total de documentos relevantes: 52\n",
            "Relevantes en top-5 inicial: 1 (20.0%)\n",
            "Relevantes en top-5 final: 3 (60.0%)\n",
            "✓ Mejora: +2 documentos relevantes\n",
            "\n",
            "====================================================================================================\n",
            "CONSULTA: Q009\n",
            "====================================================================================================\n",
            "Título: Explainable artificial intelligence\n",
            "Descripción: Interpretability and explainability in machine learning models\n",
            "====================================================================================================\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "RESULTADOS INICIALES (FAISS) - Top 5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "1. [0709.1516] Score: 0.8604\n",
            "   Título: On Universal Prediction and Bayesian Confirmation\n",
            "   Categorías: math.ST cs.IT cs.LG math.IT stat.ML stat.TH\n",
            "   Abstract: The Bayesian framework is a well-studied and successful framework for inductive reasoning, which includes hypothesis testing and confirmation, parameter estimation, sequence prediction, classification...\n",
            "   URL: https://arxiv.org/abs/0709.1516\n",
            "\n",
            "2. [0708.1071] Score: 0.8448\n",
            "   Título: Statistical thinking: From Tukey to Vardi and beyond\n",
            "   Categorías: math.ST stat.TH\n",
            "   Abstract: Data miners (minors?) and neural networkers tend to eschew modelling, misled perhaps by misinterpretation of strongly expressed views of John Tukey. I discuss Vardi's views of these issues as well as ...\n",
            "   URL: https://arxiv.org/abs/0708.1071\n",
            "\n",
            "3. [0709.0674] Score: 0.8374\n",
            "   Título: Simple Algorithmic Principles of Discovery, Subjective Beauty, Selective  Attention, Curiosity & Creativity\n",
            "   Categorías: cs.AI cs.GR\n",
            "   Abstract: I postulate that human or other intelligent agents function or should function as follows. They store all sensory observations as they come - the data is holy. At any time, given some agent's current ...\n",
            "   URL: https://arxiv.org/abs/0709.0674\n",
            "\n",
            "4. [0706.3639] Score: 0.8347\n",
            "   Título: A Collection of Definitions of Intelligence\n",
            "   Categorías: cs.AI\n",
            "   Abstract: This paper is a survey of a large number of informal definitions of ``intelligence'' that the authors have collected over the years. Naturally, compiling a complete list would be impossible as many de...\n",
            "   URL: https://arxiv.org/abs/0706.3639\n",
            "\n",
            "5. [0709.4242] Score: 0.8338\n",
            "   Título: Rational Expectations, psychology and inductive learning via moving  thresholds\n",
            "   Categorías: q-fin.TR physics.comp-ph\n",
            "   Abstract: This work suggests modifications to a previously introduced class of heterogeneous agent models that allow for the inclusion of different types of agent motivations and behaviours in a unified way. Th...\n",
            "   URL: https://arxiv.org/abs/0709.4242\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "RESULTADOS FINALES (Re-ranking) - Top 5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "1. [0708.4311] Score: -3.7469\n",
            "   Título: 2006: Celebrating 75 years of AI - History and Outlook: the Next 25  Years\n",
            "   Categorías: cs.AI\n",
            "   Abstract: When Kurt Goedel layed the foundations of theoretical computer science in 1931, he also introduced essential concepts of the theory of Artificial Intelligence (AI). Although much of subsequent AI rese...\n",
            "   URL: https://arxiv.org/abs/0708.4311\n",
            "\n",
            "2. [0709.1948] Score: -4.2539\n",
            "   Título: Information theoretic approach to interactive learning\n",
            "   Categorías: physics.data-an physics.bio-ph\n",
            "   Abstract: The principles of statistical mechanics and information theory play an important role in learning and have inspired both theory and the design of numerous machine learning algorithms. The new aspect i...\n",
            "   URL: https://arxiv.org/abs/0709.1948\n",
            "\n",
            "3. [0709.3535] Score: -6.4699\n",
            "   Título: Maximum Likelihood Estimation in Latent Class Models For Contingency  Table Data\n",
            "   Categorías: stat.ME math.ST stat.TH\n",
            "   Abstract: Statistical models with latent structure have a history going back to the 1950s and have seen widespread use in the social sciences and, more recently, in computational biology and in machine learning...\n",
            "   URL: https://arxiv.org/abs/0709.3535\n",
            "\n",
            "4. [0707.0303] Score: -6.7591\n",
            "   Título: Learning from dependent observations\n",
            "   Categorías: stat.ML stat.ME\n",
            "   Abstract: In most papers establishing consistency for learning algorithms it is assumed that the observations used for training are realizations of an i.i.d. process. In this paper we go far beyond this classic...\n",
            "   URL: https://arxiv.org/abs/0707.0303\n",
            "\n",
            "5. [0709.0674] Score: -7.5951\n",
            "   Título: Simple Algorithmic Principles of Discovery, Subjective Beauty, Selective  Attention, Curiosity & Creativity\n",
            "   Categorías: cs.AI cs.GR\n",
            "   Abstract: I postulate that human or other intelligent agents function or should function as follows. They store all sensory observations as they come - the data is holy. At any time, given some agent's current ...\n",
            "   URL: https://arxiv.org/abs/0709.0674\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "ANÁLISIS DE RELEVANCIA (basado en qrels)\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Total de documentos relevantes: 20\n",
            "Relevantes en top-5 inicial: 1 (20.0%)\n",
            "Relevantes en top-5 final: 0 (0.0%)\n",
            "⚠ Disminución: -1 documentos relevantes\n",
            "\n",
            "====================================================================================================\n",
            "CONSULTA: Q010\n",
            "====================================================================================================\n",
            "Título: Federated learning privacy\n",
            "Descripción: Federated learning and privacy-preserving machine learning\n",
            "====================================================================================================\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "RESULTADOS INICIALES (FAISS) - Top 5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "1. [0704.3905] Score: 0.7848\n",
            "   Título: Ensemble Learning for Free with Evolutionary Algorithms ?\n",
            "   Categorías: cs.AI\n",
            "   Abstract: Evolutionary Learning proceeds by evolving a population of classifiers, from which it generally returns (with some notable exceptions) the single best-of-run classifier as final result. In the meanwhi...\n",
            "   URL: https://arxiv.org/abs/0704.3905\n",
            "\n",
            "2. [0708.0261] Score: 0.7748\n",
            "   Título: An Introduction to Quantum Computing\n",
            "   Categorías: quant-ph\n",
            "   Abstract: Quantum Computing is a new and exciting field at the intersection of mathematics, computer science and physics. It concerns a utilization of quantum mechanics to improve the efficiency of computation....\n",
            "   URL: https://arxiv.org/abs/0708.0261\n",
            "\n",
            "3. [0708.3900] Score: 0.7709\n",
            "   Título: Inference from correlated patterns: a unified theory for perceptron  learning and linear vector channels\n",
            "   Categorías: cs.IT cond-mat.dis-nn math.IT\n",
            "   Abstract: A framework to analyze inference performance in densely connected single-layer feed-forward networks is developed for situations where a given data set is composed of correlated patterns. The framewor...\n",
            "   URL: https://arxiv.org/abs/0708.3900\n",
            "\n",
            "4. [0704.1764] Score: 0.7689\n",
            "   Título: Another Riemann-Farey Computation\n",
            "   Categorías: math.GM\n",
            "   Abstract: Another approach to constructing an upper bound for the Riemann-Farey sum is described....\n",
            "   URL: https://arxiv.org/abs/0704.1764\n",
            "\n",
            "5. [0705.2076] Score: 0.7649\n",
            "   Título: Notes on the log minimal model program\n",
            "   Categorías: math.AG\n",
            "   Abstract: This preprint has been withdrawn. It is because I will never publish this preprint since everything has been contained in my new preprint: arXiv:0907.1506. Please refer to arXiv:0907.1506. Please do n...\n",
            "   URL: https://arxiv.org/abs/0705.2076\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "RESULTADOS FINALES (Re-ranking) - Top 5\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "1. [0704.1274] Score: -3.9319\n",
            "   Título: Parametric Learning and Monte Carlo Optimization\n",
            "   Categorías: cs.LG\n",
            "   Abstract: This paper uncovers and explores the close relationship between Monte Carlo Optimization of a parametrized integral (MCO), Parametric machine-Learning (PL), and `blackbox' or `oracle'-based optimizati...\n",
            "   URL: https://arxiv.org/abs/0704.1274\n",
            "\n",
            "2. [0704.3905] Score: -4.1657\n",
            "   Título: Ensemble Learning for Free with Evolutionary Algorithms ?\n",
            "   Categorías: cs.AI\n",
            "   Abstract: Evolutionary Learning proceeds by evolving a population of classifiers, from which it generally returns (with some notable exceptions) the single best-of-run classifier as final result. In the meanwhi...\n",
            "   URL: https://arxiv.org/abs/0704.3905\n",
            "\n",
            "3. [0707.0303] Score: -4.4427\n",
            "   Título: Learning from dependent observations\n",
            "   Categorías: stat.ML stat.ME\n",
            "   Abstract: In most papers establishing consistency for learning algorithms it is assumed that the observations used for training are realizations of an i.i.d. process. In this paper we go far beyond this classic...\n",
            "   URL: https://arxiv.org/abs/0707.0303\n",
            "\n",
            "4. [0709.2760] Score: -4.7761\n",
            "   Título: Supervised Machine Learning with a Novel Kernel Density Estimator\n",
            "   Categorías: stat.ML\n",
            "   Abstract: In recent years, kernel density estimation has been exploited by computer scientists to model machine learning problems. The kernel density estimation based approaches are of interest due to the low t...\n",
            "   URL: https://arxiv.org/abs/0709.2760\n",
            "\n",
            "5. [0705.2328] Score: -5.7975\n",
            "   Título: On the realignment criterion and beyond\n",
            "   Categorías: quant-ph\n",
            "   Abstract: The content of this paper is now available as part of arXiv:0802.2019...\n",
            "   URL: https://arxiv.org/abs/0705.2328\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "ANÁLISIS DE RELEVANCIA (basado en qrels)\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Total de documentos relevantes: 16\n",
            "Relevantes en top-5 inicial: 0 (0.0%)\n",
            "Relevantes en top-5 final: 0 (0.0%)\n",
            "= Sin cambio en documentos relevantes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. EVALUACIÓN DEL SISTEMA\n",
        "Explicación: Evaluaremos el desempeño del sistema con métricas estándar:\n",
        "\n",
        "Precision@k: % de documentos relevantes entre los top-k recuperados\n",
        "\n",
        "Recall@k: % de documentos relevantes totales que están en top-k\n",
        "\n",
        "Compararemos inicial vs re-ranking para medir la mejora"
      ],
      "metadata": {
        "id": "ZG9HOZMImUlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_precision_at_k(retrieved_docs, relevant_docs, k):\n",
        "    \"\"\"\n",
        "    Precision@k = (# docs relevantes en top-k) / k\n",
        "    \"\"\"\n",
        "    retrieved_k = retrieved_docs[:k]\n",
        "    relevant_retrieved = len(set(retrieved_k) & set(relevant_docs))\n",
        "    return relevant_retrieved / k if k > 0 else 0\n",
        "\n",
        "def calculate_recall_at_k(retrieved_docs, relevant_docs, k):\n",
        "    \"\"\"\n",
        "    Recall@k = (# docs relevantes en top-k) / (# total docs relevantes)\n",
        "    \"\"\"\n",
        "    retrieved_k = retrieved_docs[:k]\n",
        "    relevant_retrieved = len(set(retrieved_k) & set(relevant_docs))\n",
        "    total_relevant = len(relevant_docs)\n",
        "    return relevant_retrieved / total_relevant if total_relevant > 0 else 0\n",
        "\n",
        "def evaluate_system(results, qrels_df, k_values=[5, 10, 20]):\n",
        "    \"\"\"\n",
        "    Evalúa el sistema calculando métricas para todos los k especificados\n",
        "    \"\"\"\n",
        "    metrics = defaultdict(list)\n",
        "    query_metrics = {}\n",
        "\n",
        "    for query_id, result in results.items():\n",
        "        # Obtener documentos relevantes\n",
        "        relevant_docs = qrels_df[\n",
        "            (qrels_df['query_id'] == query_id) &\n",
        "            (qrels_df['relevance'] > 0)\n",
        "        ]['doc_id'].tolist()\n",
        "\n",
        "        if len(relevant_docs) == 0:\n",
        "            continue\n",
        "\n",
        "        retrieved_docs = result['doc_ids']\n",
        "        query_metrics[query_id] = {}\n",
        "\n",
        "        for k in k_values:\n",
        "            precision = calculate_precision_at_k(retrieved_docs, relevant_docs, k)\n",
        "            recall = calculate_recall_at_k(retrieved_docs, relevant_docs, k)\n",
        "\n",
        "            metrics[f'P@{k}'].append(precision)\n",
        "            metrics[f'R@{k}'].append(recall)\n",
        "\n",
        "            query_metrics[query_id][f'P@{k}'] = precision\n",
        "            query_metrics[query_id][f'R@{k}'] = recall\n",
        "\n",
        "    # Calcular promedios\n",
        "    avg_metrics = {metric: np.mean(values) for metric, values in metrics.items()}\n",
        "\n",
        "    return avg_metrics, query_metrics\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"EVALUACIÓN DEL SISTEMA\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "# Evaluar recuperación inicial\n",
        "print(\"\\nEvaluando RECUPERACIÓN INICIAL (FAISS)...\")\n",
        "initial_metrics, initial_query_metrics = evaluate_system(initial_results, qrels_df, k_values=[5, 10, 20])\n",
        "\n",
        "print(f\"\\n{'─'*50}\")\n",
        "print(\"MÉTRICAS - RECUPERACIÓN INICIAL\")\n",
        "print(f\"{'─'*50}\")\n",
        "for metric in sorted(initial_metrics.keys()):\n",
        "    print(f\"{metric:8s}: {initial_metrics[metric]:.4f}\")\n",
        "\n",
        "# Evaluar re-ranking\n",
        "print(\"\\n\\nEvaluando RESULTADOS CON RE-RANKING...\")\n",
        "final_metrics, final_query_metrics = evaluate_system(final_results, qrels_df, k_values=[5, 10, 20])\n",
        "\n",
        "print(f\"\\n{'─'*50}\")\n",
        "print(\"MÉTRICAS - DESPUÉS DE RE-RANKING\")\n",
        "print(f\"{'─'*50}\")\n",
        "for metric in sorted(final_metrics.keys()):\n",
        "    print(f\"{metric:8s}: {final_metrics[metric]:.4f}\")"
      ],
      "metadata": {
        "id": "Ykh-74EhmYkp",
        "outputId": "8c8a5984-c532-427e-b94b-b6a7402f2988",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "EVALUACIÓN DEL SISTEMA\n",
            "====================================================================================================\n",
            "\n",
            "Evaluando RECUPERACIÓN INICIAL (FAISS)...\n",
            "\n",
            "──────────────────────────────────────────────────\n",
            "MÉTRICAS - RECUPERACIÓN INICIAL\n",
            "──────────────────────────────────────────────────\n",
            "P@10    : 0.2100\n",
            "P@20    : 0.2050\n",
            "P@5     : 0.2400\n",
            "R@10    : 0.0440\n",
            "R@20    : 0.0701\n",
            "R@5     : 0.0239\n",
            "\n",
            "\n",
            "Evaluando RESULTADOS CON RE-RANKING...\n",
            "\n",
            "──────────────────────────────────────────────────\n",
            "MÉTRICAS - DESPUÉS DE RE-RANKING\n",
            "──────────────────────────────────────────────────\n",
            "P@10    : 0.2700\n",
            "P@20    : 0.2300\n",
            "P@5     : 0.3000\n",
            "R@10    : 0.0465\n",
            "R@20    : 0.0779\n",
            "R@5     : 0.0255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Métricas por consulta\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"MÉTRICAS POR CONSULTA\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "metrics_comparison = []\n",
        "\n",
        "for query_id in queries_df['query_id']:\n",
        "    query_title = queries_df[queries_df['query_id'] == query_id].iloc[0]['title']\n",
        "\n",
        "    print(f\"\\n{query_id}: {query_title}\")\n",
        "    print(f\"{'─'*80}\")\n",
        "\n",
        "    if query_id in initial_query_metrics and query_id in final_query_metrics:\n",
        "        print(f\"{'Métrica':<10} {'Inicial':<12} {'Re-ranking':<12} {'Mejora':<10}\")\n",
        "        print(f\"{'-'*44}\")\n",
        "\n",
        "        for k in [5, 10, 20]:\n",
        "            for metric_type in ['P', 'R']:\n",
        "                metric_name = f'{metric_type}@{k}'\n",
        "                initial_val = initial_query_metrics[query_id].get(metric_name, 0)\n",
        "                final_val = final_query_metrics[query_id].get(metric_name, 0)\n",
        "                improvement = final_val - initial_val\n",
        "\n",
        "                print(f\"{metric_name:<10} {initial_val:<12.4f} {final_val:<12.4f} {improvement:+.4f}\")\n",
        "\n",
        "                metrics_comparison.append({\n",
        "                    'query_id': query_id,\n",
        "                    'metric': metric_name,\n",
        "                    'initial': initial_val,\n",
        "                    'final': final_val,\n",
        "                    'improvement': improvement\n",
        "                })\n",
        "\n",
        "# Convertir a DataFrame para análisis\n",
        "metrics_comp_df = pd.DataFrame(metrics_comparison)"
      ],
      "metadata": {
        "id": "UpPEIx6tmg1Y",
        "outputId": "027e83c2-3484-4a35-fead-ac853c7349ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "MÉTRICAS POR CONSULTA\n",
            "====================================================================================================\n",
            "\n",
            "Q001: Deep learning convolutional neural networks\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "Métrica    Inicial      Re-ranking   Mejora    \n",
            "--------------------------------------------\n",
            "P@5        0.4000       0.6000       +0.2000\n",
            "R@5        0.0400       0.0600       +0.0200\n",
            "P@10       0.2000       0.4000       +0.2000\n",
            "R@10       0.0400       0.0800       +0.0400\n",
            "P@20       0.2500       0.2500       +0.0000\n",
            "R@20       0.1000       0.1000       +0.0000\n",
            "\n",
            "Q002: Natural language processing transformer models\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "Métrica    Inicial      Re-ranking   Mejora    \n",
            "--------------------------------------------\n",
            "P@5        0.0000       0.4000       +0.4000\n",
            "R@5        0.0000       0.0488       +0.0488\n",
            "P@10       0.1000       0.3000       +0.2000\n",
            "R@10       0.0244       0.0732       +0.0488\n",
            "P@20       0.1500       0.2000       +0.0500\n",
            "R@20       0.0732       0.0976       +0.0244\n",
            "\n",
            "Q003: Reinforcement learning algorithms\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "Métrica    Inicial      Re-ranking   Mejora    \n",
            "--------------------------------------------\n",
            "P@5        0.2000       0.4000       +0.2000\n",
            "R@5        0.0152       0.0303       +0.0152\n",
            "P@10       0.2000       0.4000       +0.2000\n",
            "R@10       0.0303       0.0606       +0.0303\n",
            "P@20       0.2000       0.2500       +0.0500\n",
            "R@20       0.0606       0.0758       +0.0152\n",
            "\n",
            "Q004: Graph neural networks\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "Métrica    Inicial      Re-ranking   Mejora    \n",
            "--------------------------------------------\n",
            "P@5        0.0000       0.0000       +0.0000\n",
            "R@5        0.0000       0.0000       +0.0000\n",
            "P@10       0.0000       0.0000       +0.0000\n",
            "R@10       0.0000       0.0000       +0.0000\n",
            "P@20       0.0000       0.0000       +0.0000\n",
            "R@20       0.0000       0.0000       +0.0000\n",
            "\n",
            "Q005: Quantum computing algorithms\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "Métrica    Inicial      Re-ranking   Mejora    \n",
            "--------------------------------------------\n",
            "P@5        1.0000       0.8000       -0.2000\n",
            "R@5        0.0035       0.0028       -0.0007\n",
            "P@10       0.9000       0.9000       +0.0000\n",
            "R@10       0.0062       0.0062       +0.0000\n",
            "P@20       0.9500       0.9500       +0.0000\n",
            "R@20       0.0131       0.0131       +0.0000\n",
            "\n",
            "Q006: Generative adversarial networks\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "Métrica    Inicial      Re-ranking   Mejora    \n",
            "--------------------------------------------\n",
            "P@5        0.0000       0.0000       +0.0000\n",
            "R@5        0.0000       0.0000       +0.0000\n",
            "P@10       0.1000       0.0000       -0.1000\n",
            "R@10       0.0769       0.0000       -0.0769\n",
            "P@20       0.1000       0.0500       -0.0500\n",
            "R@20       0.1538       0.0769       -0.0769\n",
            "\n",
            "Q007: Transfer learning domain adaptation\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "Métrica    Inicial      Re-ranking   Mejora    \n",
            "--------------------------------------------\n",
            "P@5        0.4000       0.2000       -0.2000\n",
            "R@5        0.1111       0.0556       -0.0556\n",
            "P@10       0.2000       0.1000       -0.1000\n",
            "R@10       0.1111       0.0556       -0.0556\n",
            "P@20       0.1000       0.0500       -0.0500\n",
            "R@20       0.1111       0.0556       -0.0556\n",
            "\n",
            "Q008: Time series forecasting\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "Métrica    Inicial      Re-ranking   Mejora    \n",
            "--------------------------------------------\n",
            "P@5        0.2000       0.6000       +0.4000\n",
            "R@5        0.0192       0.0577       +0.0385\n",
            "P@10       0.2000       0.4000       +0.2000\n",
            "R@10       0.0385       0.0769       +0.0385\n",
            "P@20       0.2000       0.3500       +0.1500\n",
            "R@20       0.0769       0.1346       +0.0577\n",
            "\n",
            "Q009: Explainable artificial intelligence\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "Métrica    Inicial      Re-ranking   Mejora    \n",
            "--------------------------------------------\n",
            "P@5        0.2000       0.0000       -0.2000\n",
            "R@5        0.0500       0.0000       -0.0500\n",
            "P@10       0.1000       0.1000       +0.0000\n",
            "R@10       0.0500       0.0500       +0.0000\n",
            "P@20       0.0500       0.1000       +0.0500\n",
            "R@20       0.0500       0.1000       +0.0500\n",
            "\n",
            "Q010: Federated learning privacy\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "Métrica    Inicial      Re-ranking   Mejora    \n",
            "--------------------------------------------\n",
            "P@5        0.0000       0.0000       +0.0000\n",
            "R@5        0.0000       0.0000       +0.0000\n",
            "P@10       0.1000       0.1000       +0.0000\n",
            "R@10       0.0625       0.0625       +0.0000\n",
            "P@20       0.0500       0.1000       +0.0500\n",
            "R@20       0.0625       0.1250       +0.0625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. ANÁLISIS DE RESULTADOS\n",
        "\n",
        "Análisis de mejoras del re-ranking\n",
        "\n",
        "Identificación de consultas con mayor/menor mejora"
      ],
      "metadata": {
        "id": "rNxubbd0mlIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Análisis detallado de mejoras\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"ANÁLISIS DETALLADO DE MEJORAS\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "print(f\"\\n{'Métrica':<10} {'Inicial':<12} {'Re-ranking':<12} {'Diferencia':<12} {'Mejora %':<10}\")\n",
        "print(f\"{'─'*70}\")\n",
        "\n",
        "for metric in metrics_names:\n",
        "    initial = initial_metrics.get(metric, 0)\n",
        "    final = final_metrics.get(metric, 0)\n",
        "    diff = final - initial\n",
        "    mejora_pct = (diff / initial * 100) if initial > 0 else 0\n",
        "\n",
        "    symbol = \"✓\" if diff > 0 else (\"=\" if diff == 0 else \"✗\")\n",
        "\n",
        "    print(f\"{metric:<10} {initial:<12.4f} {final:<12.4f} {diff:<+12.4f} {mejora_pct:+8.2f}% {symbol}\")\n",
        "\n",
        "# Promedio de mejora\n",
        "avg_improvement = np.mean([\n",
        "    ((final_metrics.get(m, 0) - initial_metrics.get(m, 0)) / initial_metrics.get(m, 1) * 100)\n",
        "    for m in metrics_names if initial_metrics.get(m, 0) > 0\n",
        "])\n",
        "\n",
        "print(f\"\\n{'─'*70}\")\n",
        "print(f\"Mejora promedio: {avg_improvement:+.2f}%\")"
      ],
      "metadata": {
        "id": "uivYE1QFmu9f",
        "outputId": "ab541b28-e391-414b-da47-0ea1511433de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "ANÁLISIS DETALLADO DE MEJORAS\n",
            "====================================================================================================\n",
            "\n",
            "Métrica    Inicial      Re-ranking   Diferencia   Mejora %  \n",
            "──────────────────────────────────────────────────────────────────────\n",
            "P@5        0.2400       0.3000       +0.0600        +25.00% ✓\n",
            "P@10       0.2100       0.2700       +0.0600        +28.57% ✓\n",
            "P@20       0.2050       0.2300       +0.0250        +12.20% ✓\n",
            "R@5        0.0239       0.0255       +0.0016         +6.76% ✓\n",
            "R@10       0.0440       0.0465       +0.0025         +5.70% ✓\n",
            "R@20       0.0701       0.0779       +0.0077        +11.02% ✓\n",
            "\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "Mejora promedio: +14.87%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "total_docs = len(docs_df)\n",
        "total_queries = len(queries_df)\n",
        "total_qrels = len(qrels_df)\n",
        "avg_relevant_per_query = total_qrels / total_queries if total_queries > 0 else 0\n",
        "\n",
        "# Calcular mejora promedio en P@10\n",
        "p10_initial = initial_metrics.get('P@10', 0)\n",
        "p10_final = final_metrics.get('P@10', 0)\n",
        "p10_improvement = ((p10_final - p10_initial) / p10_initial * 100) if p10_initial > 0 else 0\n",
        "\n",
        "print(f\"\"\"\n",
        "\n",
        "\n",
        "Dataset:                    arXiv Scientific Papers\n",
        "Papers procesados:          {total_docs:,}\n",
        "Consultas evaluadas:        {total_queries}\n",
        "Qrels generados:            {total_qrels:,}\n",
        "Relevantes por consulta:    {avg_relevant_per_query:.1f} (promedio)\n",
        "\n",
        "Modelos utilizados:\n",
        "  • Embeddings:             {embedding_model.get_sentence_embedding_dimension()}D - allenai-specter / all-MiniLM-L6-v2\n",
        "  • Re-ranking:             cross-encoder/ms-marco-MiniLM-L-6-v2\n",
        "\n",
        "Parámetros:\n",
        "  • Top-k inicial (FAISS):  {k_initial}\n",
        "  • Top-k final:            {top_k_final}\n",
        "  • Batch size:             {batch_size}\n",
        "\n",
        "{'─'*100}\n",
        "MÉTRICAS DE RENDIMIENTO\n",
        "{'─'*100}\n",
        "\n",
        "Recuperación Inicial (FAISS):\n",
        "  Precision@5:              {initial_metrics.get('P@5', 0):.4f}\n",
        "  Precision@10:             {initial_metrics.get('P@10', 0):.4f}\n",
        "  Precision@20:             {initial_metrics.get('P@20', 0):.4f}\n",
        "  Recall@10:                {initial_metrics.get('R@10', 0):.4f}\n",
        "\n",
        "Después de Re-ranking:\n",
        "  Precision@5:              {final_metrics.get('P@5', 0):.4f}  ({((final_metrics.get('P@5', 0) - initial_metrics.get('P@5', 0)) / initial_metrics.get('P@5', 1) * 100):+.1f}%)\n",
        "  Precision@10:             {final_metrics.get('P@10', 0):.4f}  ({p10_improvement:+.1f}%)\n",
        "  Precision@20:             {final_metrics.get('P@20', 0):.4f}  ({((final_metrics.get('P@20', 0) - initial_metrics.get('P@20', 0)) / initial_metrics.get('P@20', 1) * 100):+.1f}%)\n",
        "  Recall@10:                {final_metrics.get('R@10', 0):.4f}  ({((final_metrics.get('R@10', 0) - initial_metrics.get('R@10', 0)) / initial_metrics.get('R@10', 1) * 100):+.1f}%)\n",
        "\n",
        "Mejora promedio general:    {avg_improvement:+.2f}%\n",
        "\n",
        "{'─'*100}\n",
        "CONCLUSIONES\n",
        "{'─'*100}\n",
        "\n",
        "✓ FORTALEZAS DEL SISTEMA:\n",
        "  1. Búsqueda semántica eficiente con FAISS permite procesar miles de documentos\n",
        "  2. Embeddings especializados (SPECTER) capturan contexto científico\n",
        "  3. Re-ranking con Cross-Encoder mejora significativamente la precisión\n",
        "  4. Sistema escalable para millones de papers\n",
        "\n",
        "✓ IMPACTO DEL RE-RANKING:\n",
        "  • Mejora consistente en Precision@k (especialmente k pequeños)\n",
        "  • Documentos más relevantes en primeras posiciones\n",
        "  • Balance óptimo entre eficiencia (FAISS) y calidad (Cross-Encoder)\n",
        "\n",
        "✓ APLICACIONES POTENCIALES:\n",
        "  • Motor de búsqueda académica\n",
        "  • Sistema de recomendación de papers\n",
        "  • Análisis de tendencias en investigación\n",
        "  • Identificación de trabajos relacionados\n",
        "  • Construcción de grafos de conocimiento científico\n",
        "\n",
        "⚠ LIMITACIONES Y MEJORAS FUTURAS:\n",
        "  1. Qrels automáticos (idealmente usar juicios humanos)\n",
        "  2. Expandir a más categorías científicas\n",
        "  3. Integrar citaciones y métricas de impacto\n",
        "  4. Implementar búsqueda multi-modal (texto + ecuaciones + figuras)\n",
        "  5. Fine-tuning de modelos con datos específicos de arXiv\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "sWUvqKN3m2cf",
        "outputId": "1459fdf5-5bec-4f8e-cb44-ac414053b8bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Dataset:                    arXiv Scientific Papers\n",
            "Papers procesados:          29,957\n",
            "Consultas evaluadas:        10\n",
            "Qrels generados:            1,743\n",
            "Relevantes por consulta:    174.3 (promedio)\n",
            "\n",
            "Modelos utilizados:\n",
            "  • Embeddings:             768D - allenai-specter / all-MiniLM-L6-v2\n",
            "  • Re-ranking:             cross-encoder/ms-marco-MiniLM-L-6-v2\n",
            "  \n",
            "Parámetros:\n",
            "  • Top-k inicial (FAISS):  100\n",
            "  • Top-k final:            20\n",
            "  • Batch size:             32\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "MÉTRICAS DE RENDIMIENTO\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "Recuperación Inicial (FAISS):\n",
            "  Precision@5:              0.2400\n",
            "  Precision@10:             0.2100\n",
            "  Precision@20:             0.2050\n",
            "  Recall@10:                0.0440\n",
            "\n",
            "Después de Re-ranking:\n",
            "  Precision@5:              0.3000  (+25.0%)\n",
            "  Precision@10:             0.2700  (+28.6%)\n",
            "  Precision@20:             0.2300  (+12.2%)\n",
            "  Recall@10:                0.0465  (+5.7%)\n",
            "\n",
            "Mejora promedio general:    +14.87%\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "CONCLUSIONES\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "✓ FORTALEZAS DEL SISTEMA:\n",
            "  1. Búsqueda semántica eficiente con FAISS permite procesar miles de documentos\n",
            "  2. Embeddings especializados (SPECTER) capturan contexto científico\n",
            "  3. Re-ranking con Cross-Encoder mejora significativamente la precisión\n",
            "  4. Sistema escalable para millones de papers\n",
            "\n",
            "✓ IMPACTO DEL RE-RANKING:\n",
            "  • Mejora consistente en Precision@k (especialmente k pequeños)\n",
            "  • Documentos más relevantes en primeras posiciones\n",
            "  • Balance óptimo entre eficiencia (FAISS) y calidad (Cross-Encoder)\n",
            "\n",
            "✓ APLICACIONES POTENCIALES:\n",
            "  • Motor de búsqueda académica\n",
            "  • Sistema de recomendación de papers\n",
            "  • Análisis de tendencias en investigación\n",
            "  • Identificación de trabajos relacionados\n",
            "  • Construcción de grafos de conocimiento científico\n",
            "\n",
            "⚠ LIMITACIONES Y MEJORAS FUTURAS:\n",
            "  1. Qrels automáticos (idealmente usar juicios humanos)\n",
            "  2. Expandir a más categorías científicas\n",
            "  3. Integrar citaciones y métricas de impacto\n",
            "  4. Implementar búsqueda multi-modal (texto + ecuaciones + figuras)\n",
            "  5. Fine-tuning de modelos con datos específicos de arXiv\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}