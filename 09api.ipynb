{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 9: Uso de la API de Google Gemini"
      ],
      "metadata": {
        "id": "1UJpch_6mn3U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nombre: Marcela Cabrera"
      ],
      "metadata": {
        "id": "l2Yr5ErXnoy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import kagglehub\n",
        "import os"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "sDURTwhuY9h5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = \"AIzaSyDPsBV4io_VL-YzjSinjSQpfabkztYvNro\"\n",
        "genai.configure(api_key=API_KEY)\n",
        "\n",
        "# Crear el modelo\n",
        "model = genai.GenerativeModel('gemini-pro')\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "YboJDuZtY9h6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de uso básico\n",
        "def uso_basico():\n",
        "    \"\"\"Ejemplo de generación de texto con Gemini\"\"\"\n",
        "    prompt = \"Explica qué es el machine learning en 3 oraciones\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "    print(\"=== USO BÁSICO ===\")\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(f\"Respuesta: {response.text}\\n\")\n",
        "    return response.text"
      ],
      "metadata": {
        "id": "jNJQdlB8cfgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cargar_corpus(path):\n",
        "    \"\"\"Carga el dataset de 20 newsgroups desde Kaggle\"\"\"\n",
        "    print(\"=== CARGANDO CORPUS ===\")\n",
        "\n",
        "    import os\n",
        "\n",
        "    documents = []\n",
        "    train_path = os.path.join(path, '20news-bydate-train')\n",
        "     # Limitamos a algunas categorías para el ejemplo\n",
        "    categorias_interes = ['sci.space', 'comp.graphics', 'rec.sport.baseball']\n",
        "\n",
        "    for categoria in categorias_interes:\n",
        "        cat_path = os.path.join(train_path, categoria)\n",
        "\n",
        "        if os.path.exists(cat_path):\n",
        "            archivos = os.listdir(cat_path)[:20]  # Tomar 20 docs por categoría\n",
        "\n",
        "            for archivo in archivos:\n",
        "                file_path = os.path.join(cat_path, archivo)\n",
        "                try:\n",
        "                    with open(file_path, 'r', encoding='latin-1') as f:\n",
        "                        content = f.read()\n",
        "                        # Remover headers básicos\n",
        "                        if '\\n\\n' in content:\n",
        "                            content = content.split('\\n\\n', 1)[1]\n",
        "                        documents.append(content)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error leyendo {archivo}: {e}\")\n",
        "\n",
        "    print(f\"Documentos cargados: {len(documents)}\")\n",
        "    print(f\"Ejemplo de documento:\\n{documents[0][:200]}...\\n\")\n",
        "\n",
        "    return documents"
      ],
      "metadata": {
        "id": "Yx0SbZYOcm_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crear_embeddings(documents):\n",
        "    \"\"\"Convierte los documentos en embeddings usando Gemini\"\"\"\n",
        "    print(\"=== CREANDO EMBEDDINGS ===\")\n",
        "\n",
        "    embeddings = []\n",
        "\n",
        "    for i, doc in enumerate(documents):\n",
        "        # Limitar longitud del documento si es muy largo\n",
        "        doc_truncado = doc[:1000] if len(doc) > 1000 else doc\n",
        "\n",
        "        # Generar embedding usando el modelo de embeddings de Gemini\n",
        "        result = genai.embed_content(\n",
        "            model=\"models/embedding-001\",\n",
        "            content=doc_truncado,\n",
        "            task_type=\"retrieval_document\"\n",
        "        )\n",
        "\n",
        "        embeddings.append(result['embedding'])\n",
        "\n",
        "        if (i + 1) % 10 == 0:\n",
        "            print(f\"Procesados {i + 1}/{len(documents)} documentos\")\n",
        "\n",
        "    embeddings_array = np.array(embeddings)\n",
        "    print(f\"Shape de embeddings: {embeddings_array.shape}\\n\")\n",
        "\n",
        "    return embeddings_array"
      ],
      "metadata": {
        "id": "Bf95MPs7dznh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.3 Crear query y realizar búsqueda\n",
        "def buscar_documentos_similares(query, documents, embeddings_corpus, top_k=5):\n",
        "    \"\"\"Busca los documentos más similares a la query\"\"\"\n",
        "    print(\"=== BÚSQUEDA DE DOCUMENTOS SIMILARES ===\")\n",
        "    print(f\"Query: {query}\\n\")\n",
        "\n",
        "    # Crear embedding de la query\n",
        "    query_embedding = genai.embed_content(\n",
        "        model=\"models/embedding-001\",\n",
        "        content=query,\n",
        "        task_type=\"retrieval_query\"\n",
        "    )\n",
        "\n",
        "    query_vector = np.array(query_embedding['embedding']).reshape(1, -1)\n",
        "    # Calcular similitud coseno\n",
        "    similarities = cosine_similarity(query_vector, embeddings_corpus)[0]\n",
        "\n",
        "    # Obtener los índices de los top_k documentos más similares\n",
        "    top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
        "\n",
        "    print(f\"Top {top_k} documentos más similares:\\n\")\n",
        "\n",
        "    resultados = []\n",
        "    for rank, idx in enumerate(top_indices, 1):\n",
        "        score = similarities[idx]\n",
        "        doc_preview = documents[idx][:200].replace('\\n', ' ')\n",
        "\n",
        "        print(f\"{rank}. Documento {idx}\")\n",
        "        print(f\"   Similitud: {score:.4f}\")\n",
        "        print(f\"   Preview: {doc_preview}...\")\n",
        "        print()\n",
        "\n",
        "        resultados.append({\n",
        "            'rank': rank,\n",
        "            'indice': idx,\n",
        "            'similitud': score,\n",
        "            'documento': documents[idx]\n",
        "        })\n",
        "\n",
        "    return resultados\n"
      ],
      "metadata": {
        "id": "Tul2arZXfQwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# FUNCIÓN PRINCIPAL\n",
        "# ============================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Ejecuta el ejercicio completo\"\"\"\n",
        "\n",
        "    # 1. Uso básico\n",
        "    uso_basico()\n",
        "\n",
        "    # 2. Retrieval\n",
        "    # Descargar dataset de Kaggle\n",
        "    print(\"=== DESCARGANDO DATASET ===\")\n",
        "    path = kagglehub.dataset_download(\"crawford/20-newsgroups\")\n",
        "    print(f\"Path to dataset files: {path}\\n\")\n",
        "\n",
        "    # 2.1 Cargar corpus\n",
        "    documents = cargar_corpus(path)\n",
        "\n",
        "    # 2.2 Crear embeddings\n",
        "    embeddings = crear_embeddings(documents)\n",
        "\n",
        "    # 2.3 Realizar búsqueda\n",
        "    query = \"space shuttle missions and astronauts\"\n",
        "    resultados = buscar_documentos_similares(query, documents, embeddings, top_k=5)\n",
        "    # Ejemplo adicional de búsqueda\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    query2 = \"computer graphics and visualization techniques\"\n",
        "    resultados2 = buscar_documentos_similares(query2, documents, embeddings, top_k=5)\n",
        "\n"
      ],
      "metadata": {
        "id": "7zIgRRAVfXBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  # Descomentar para ejecutar:\n",
        "  main()"
      ],
      "metadata": {
        "id": "Lc5fvW9GmgIa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}